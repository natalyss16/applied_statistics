% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Exercises},
  pdfauthor={Natali Tckvitishvili},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Exercises}
\author{Natali Tckvitishvili}
\date{2024-08-17}

\begin{document}
\maketitle

\section{Applied Statistics in R}\label{applied-statistics-in-r}

\subsection{Natali Tckvitishvili}\label{natali-tckvitishvili}

\subsubsection{Load libraries}\label{load-libraries}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("extraDistr")}
\CommentTok{\#install.packages(\textquotesingle{}tinytex\textquotesingle{})}
\CommentTok{\#install.packages(\textquotesingle{}ggpubr\textquotesingle{})}
\CommentTok{\#install.packages(\textquotesingle{}tidyverse\textquotesingle{})}
\CommentTok{\#install.packages(\textquotesingle{}glmnet\textquotesingle{})}
\CommentTok{\#install.packages(\textquotesingle{}astsa\textquotesingle{})}
\CommentTok{\#install.packages(\textquotesingle{}surveillance\textquotesingle{})}
\CommentTok{\#install.packages(\textquotesingle{}JoSAE\textquotesingle{})}

\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(stats)}
\FunctionTok{library}\NormalTok{(ggpubr)}
\FunctionTok{library}\NormalTok{(extraDistr)}
\FunctionTok{library}\NormalTok{(tinytex)}
\FunctionTok{library}\NormalTok{(glmnet)}
\FunctionTok{library}\NormalTok{(astsa)}
\FunctionTok{library}\NormalTok{(surveillance)}
\FunctionTok{library}\NormalTok{(JoSAE)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Exercise 1}\label{exercise-1}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  load data \& add new variable - good
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wine }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"winequality{-}white.csv"}\NormalTok{, }\AttributeTok{sep =} \StringTok{";"}\NormalTok{)}
\NormalTok{wine }\OtherTok{\textless{}{-}} \FunctionTok{mutate}\NormalTok{(wine, }\AttributeTok{good =} \FunctionTok{ifelse}\NormalTok{(quality }\SpecialCharTok{\textgreater{}} \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}

\FunctionTok{head}\NormalTok{(wine)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  residual.sugar analysis
\end{enumerate}

First I'd specify the analysed variable to add more flexibility to the
further analysis, when we'll need to make the same calculation for
another variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{analysed\_variable }\OtherTok{\textless{}{-}}\NormalTok{ wine}\SpecialCharTok{$}\NormalTok{residual.sugar}
\NormalTok{wine}\SpecialCharTok{$}\NormalTok{analysed\_variable }\OtherTok{\textless{}{-}}\NormalTok{ analysed\_variable}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  histograms for good and bad quality wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{good\_labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"0"} \OtherTok{=} \StringTok{"bad"}\NormalTok{, }\StringTok{"1"} \OtherTok{=} \StringTok{"good"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable, }\AttributeTok{fill =} \FunctionTok{as.factor}\NormalTok{(good))) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#b37d69"}\NormalTok{, }\StringTok{"\#6dcc6b"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(good), }\AttributeTok{labeller=}\FunctionTok{labeller}\NormalTok{(}\AttributeTok{good =}\NormalTok{ good\_labels)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"Sugar residuals"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Sugar residuals by wine quality"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-4-1.pdf}}

According to the graphs, both bad and good quality wines have sugar
residuals near zero, however, for good wines this number is higher than
for bad ones. Moreover, sugar residuals of good quality wines have a
smoother decrease in frequency, most of them have less sugar. Therefore,
we can assume that sugar residuals may have negative correlation with
wine quality.

\begin{itemize}
\tightlist
\item
  summary statistics
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary }\OtherTok{\textless{}{-}}\NormalTok{ wine }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(good) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{n =} \FunctionTok{n}\NormalTok{(),}
    \AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(analysed\_variable),}
    \AttributeTok{median =} \FunctionTok{median}\NormalTok{(analysed\_variable),}
    \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(analysed\_variable),}
    \AttributeTok{iqr =} \FunctionTok{IQR}\NormalTok{(analysed\_variable),}
    \AttributeTok{max =} \FunctionTok{max}\NormalTok{(analysed\_variable),}
    \AttributeTok{min =} \FunctionTok{min}\NormalTok{(analysed\_variable)}
\NormalTok{  )}
\FunctionTok{data.frame}\NormalTok{(summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   good    n     mean median       sd   iqr  max min
## 1    0 1640 7.054451  6.625 5.283594 9.325 23.5 0.6
## 2    1 3258 6.057658  4.750 4.929353 7.400 65.8 0.7
\end{verbatim}

For the ``bad'' quality wines both mean and median of the sugar
residuals are higher than for the ``good'' wines, which probably (I say
probably here as we haven't checked the significance of this difference
yet) means that bad wines on average contain more sugar than good ones.
They also have a higher variance and range between the values which may
mean that the variety of the bad wines is bigger than of the good ones.
What is interesting, there is an observation of a good wine with 65.8
sugar residuals which is a huge number compared to the mean and median.
This might be an outlier, we'll see if that's true drawing a boxplot.
Additionally, for good wines the difference between the mean and median
is quite big, so we can assume that there are more outliers that impact
the mean.

\begin{itemize}
\tightlist
\item
  boxplots
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as.factor}\NormalTok{(good), }\AttributeTok{y =}\NormalTok{ analysed\_variable, }\AttributeTok{fill =} \FunctionTok{as.factor}\NormalTok{(good))) }\SpecialCharTok{+}
    \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#b37d69"}\NormalTok{, }\StringTok{"\#6dcc6b"}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{labels =}\NormalTok{ good\_labels) }\SpecialCharTok{+}
    \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{ (}
      \AttributeTok{x =} \StringTok{"Wine quality"}\NormalTok{,}
      \AttributeTok{y =} \StringTok{"Sugar residuals"}\NormalTok{,}
      \AttributeTok{title =} \StringTok{"Sugar residuals by wine quality"}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-6-1.pdf}}

As stated above, the good wine with 65.8 sugar residuals must be an
outlier, accoring to the boxplots. There are two more outliers, and all
of them impact the mean. Assuming that better wines on average have less
sugar, these observations might be a quality estimation error / human
factor or there are sugary wines which are considered good in the modern
somelier society.

\begin{itemize}
\tightlist
\item
  QQ plot to compare samples
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{good\_wine }\OtherTok{\textless{}{-}}\NormalTok{ wine }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(good }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}

\NormalTok{bad\_wine }\OtherTok{\textless{}{-}}\NormalTok{ wine }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(good }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}

\NormalTok{quantiles }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\NormalTok{good\_quantiles }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(good\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable, quantiles)}
\NormalTok{bad\_quantiles }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(bad\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable, quantiles)}

\NormalTok{qq\_wine }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(good\_quantiles, bad\_quantiles)}

\FunctionTok{ggplot}\NormalTok{(qq\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ good\_quantiles, }\AttributeTok{y =}\NormalTok{ bad\_quantiles)) }\SpecialCharTok{+}
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{intercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{color =} \StringTok{"\#de4dd9"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(good\_quantiles, bad\_quantiles)) }\SpecialCharTok{+}
    \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(good\_quantiles, bad\_quantiles)) }\SpecialCharTok{+}
    \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"QQ Plot: good vs bad wines"}\NormalTok{,}
         \AttributeTok{x =} \StringTok{"Quantiles of good wines"}\NormalTok{,}
         \AttributeTok{y =} \StringTok{"Quantiles of bad wines"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-7-1.pdf}}

The distribution of both samples seems to be similar and right-skewed
(this can also be seen on the histograms above). We also see here the
outlier.

\begin{itemize}
\tightlist
\item
  Empirical distribution functions
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable, }\AttributeTok{color =} \FunctionTok{as.factor}\NormalTok{(good))) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{geom =} \StringTok{"step"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#b37d69"}\NormalTok{, }\StringTok{"\#6dcc6b"}\NormalTok{), }\AttributeTok{labels=}\NormalTok{good\_labels, }\AttributeTok{name=}\StringTok{"wine quality"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"Sugar residuals"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Cumulative probability"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Empirical distribution functions"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-8-1.pdf}}

The distribution of sugar residuals in good wines is more concentrated
around lower values than bad wines. Moreover, values are spread out
(graphs are smooth).

All of those graphs and summary statistics show the same: good wines in
general have lower sugar residuals than bad ones.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  volatile.acidity
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{analysed\_variable }\OtherTok{\textless{}{-}}\NormalTok{ wine}\SpecialCharTok{$}\NormalTok{volatile.acidity}
\NormalTok{wine}\SpecialCharTok{$}\NormalTok{analysed\_variable }\OtherTok{\textless{}{-}}\NormalTok{ analysed\_variable}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  histograms for good and bad quality wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable, }\AttributeTok{fill =} \FunctionTok{as.factor}\NormalTok{(good))) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#b37d69"}\NormalTok{, }\StringTok{"\#6dcc6b"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(good), }\AttributeTok{labeller=}\FunctionTok{labeller}\NormalTok{(}\AttributeTok{good =}\NormalTok{ good\_labels)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"Volatile acidity"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Volatile acidity by wine quality"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-10-1.pdf}}

It can be said that means of volatile acidity for both good and bad
wines do not seem do be significantly different, however, for good wines
it may be a little less than for the bad ones. Both distributions are a
little right-skewed as well.

\begin{itemize}
\tightlist
\item
  summary statistics
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary }\OtherTok{\textless{}{-}}\NormalTok{ wine }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(good) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{n =} \FunctionTok{n}\NormalTok{(),}
    \AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(analysed\_variable),}
    \AttributeTok{median =} \FunctionTok{median}\NormalTok{(analysed\_variable),}
    \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(analysed\_variable),}
    \AttributeTok{iqr =} \FunctionTok{IQR}\NormalTok{(analysed\_variable),}
    \AttributeTok{max =} \FunctionTok{max}\NormalTok{(analysed\_variable),}
    \AttributeTok{min =} \FunctionTok{min}\NormalTok{(analysed\_variable)}
\NormalTok{  )}
\FunctionTok{data.frame}\NormalTok{(summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   good    n      mean median        sd  iqr   max  min
## 1    0 1640 0.3102652   0.29 0.1125479 0.11 1.100 0.10
## 2    1 3258 0.2621209   0.25 0.0901360 0.11 0.965 0.08
\end{verbatim}

Similarly to sugar residual, for the ``bad'' quality wines both mean and
median of the volatile acidity are higher than for the ``good'' wines,
although difference is not that huge.

\begin{itemize}
\tightlist
\item
  boxplots
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as.factor}\NormalTok{(good), }\AttributeTok{y =}\NormalTok{ analysed\_variable, }\AttributeTok{fill =} \FunctionTok{as.factor}\NormalTok{(good))) }\SpecialCharTok{+}
    \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#b37d69"}\NormalTok{, }\StringTok{"\#6dcc6b"}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{labels =}\NormalTok{ good\_labels) }\SpecialCharTok{+}
    \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{ (}
      \AttributeTok{x =} \StringTok{"Wine quality"}\NormalTok{,}
      \AttributeTok{y =} \StringTok{"Volatile acidity"}\NormalTok{,}
      \AttributeTok{title =} \StringTok{"Volatile acidity by wine quality"}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-12-1.pdf}}

Looks like we have much more outliers here than in sugar residuals. In
general, bad wines seem to have more acids (boxplot is located higher).

\begin{itemize}
\tightlist
\item
  QQ plot to compare samples
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{good\_quantiles }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(good\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable, quantiles)}
\NormalTok{bad\_quantiles }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(bad\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable, quantiles)}

\NormalTok{qq\_wine }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(good\_quantiles, bad\_quantiles)}

\FunctionTok{ggplot}\NormalTok{(qq\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ good\_quantiles, }\AttributeTok{y =}\NormalTok{ bad\_quantiles)) }\SpecialCharTok{+}
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{intercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{color =} \StringTok{"\#de4dd9"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(good\_quantiles, bad\_quantiles)) }\SpecialCharTok{+}
    \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(good\_quantiles, bad\_quantiles)) }\SpecialCharTok{+}
    \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"QQ Plot: good vs bad wines"}\NormalTok{,}
         \AttributeTok{x =} \StringTok{"Quantiles of good wines"}\NormalTok{,}
         \AttributeTok{y =} \StringTok{"Quantiles of bad wines"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-13-1.pdf}}

The distribution of both samples seems to be similar but with a
difference in scal (variance) as dots do not fall on the y = x line, but
still form the straight line.

\begin{itemize}
\tightlist
\item
  Empirical distribution functions
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable, }\AttributeTok{color =} \FunctionTok{as.factor}\NormalTok{(good))) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{geom =} \StringTok{"step"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\StringTok{"\#b37d69"}\NormalTok{, }\StringTok{"\#6dcc6b"}\NormalTok{), }\AttributeTok{labels=}\NormalTok{good\_labels, }\AttributeTok{name=}\StringTok{"wine quality"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"Volatile acidity"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Cumulative probability"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Empirical distribution functions"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-14-1.pdf}}

Good wines have generally lower values that bad ones; steepness
demonstrates that a large number of observations is concentrated within
a small range of values. Generally, all graphs incicate that good wines
tend to have lower volatile acidity than bad wines.

\subsubsection{Exercise 2}\label{exercise-2}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{analysed\_variable }\OtherTok{\textless{}{-}}\NormalTok{ wine}\SpecialCharTok{$}\NormalTok{pH}
\NormalTok{wine}\SpecialCharTok{$}\NormalTok{analysed\_variable }\OtherTok{\textless{}{-}}\NormalTok{ analysed\_variable}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  histogram
\end{enumerate}

mean and standard deviation for plotting normal density

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean\_pH }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(wine}\SpecialCharTok{$}\NormalTok{analysed\_variable)}
\NormalTok{sd\_pH }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(wine}\SpecialCharTok{$}\NormalTok{analysed\_variable)}

\NormalTok{mean\_pH}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.188267
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd\_pH}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1510006
\end{verbatim}

\begin{itemize}
\tightlist
\item
  all wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#6a6ad9"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =} \ControlFlowTok{function}\NormalTok{(x) }\CommentTok{\# scale normal density to be seen}
    \FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =}\NormalTok{ mean\_pH, }\AttributeTok{sd =}\NormalTok{ sd\_pH) }\SpecialCharTok{*} \DecValTok{70}\NormalTok{, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#d27786"}\NormalTok{), }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"pH"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"pH and normal density"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-17-1.pdf}}

\begin{itemize}
\tightlist
\item
  good and bad wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{good\_wine }\OtherTok{\textless{}{-}}\NormalTok{ wine }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(good }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}

\NormalTok{bad\_wine }\OtherTok{\textless{}{-}}\NormalTok{ wine }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(good }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}

\NormalTok{mean\_pH\_good }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(good\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable)}
\NormalTok{sd\_pH\_good }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(good\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable)}

\NormalTok{mean\_pH\_bad }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(bad\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable)}
\NormalTok{sd\_pH\_bad }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(bad\_wine}\SpecialCharTok{$}\NormalTok{analysed\_variable)}

\NormalTok{mean\_pH\_good}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.197231
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd\_pH\_good}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1535172
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean\_pH\_bad}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.170457
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd\_pH\_bad}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1442744
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(good\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#6dcc6b"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =} \ControlFlowTok{function}\NormalTok{(x) }
    \FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =}\NormalTok{ mean\_pH\_good, }\AttributeTok{sd =}\NormalTok{ sd\_pH\_good) }\SpecialCharTok{*} \DecValTok{40}\NormalTok{, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#d27786"}\NormalTok{), }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"pH"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"pH for good wines"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-19-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(bad\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#b37d69"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =} \ControlFlowTok{function}\NormalTok{(x) }
    \FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =}\NormalTok{ mean\_pH\_bad, }\AttributeTok{sd =}\NormalTok{ sd\_pH\_bad) }\SpecialCharTok{*} \DecValTok{20}\NormalTok{, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#d27786"}\NormalTok{), }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"pH"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"pH for bad wines"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-20-1.pdf}}

It can be said that pH follows the normal distribution for bad wines,
but for good wines and wines in total the distribution seems to be
bimodal with two peaks.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  QQ plots
\end{enumerate}

\begin{itemize}
\tightlist
\item
  all wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qq\_all }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  good wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qq\_good }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(good\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  bad wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qq\_bad }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(bad\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )  }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggarrange}\NormalTok{(qq\_all, qq\_good, qq\_bad, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"all"}\NormalTok{, }\StringTok{"good"}\NormalTok{, }\StringTok{"bad"}\NormalTok{), }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-24-1.pdf}}
b. PP plots

\begin{itemize}
\tightlist
\item
  all wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pp\_all }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{(}\AttributeTok{distribution =}\NormalTok{ qnorm, }\AttributeTok{dparams =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ mean\_pH, }\AttributeTok{sd =}\NormalTok{ sd\_pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{distribution =}\NormalTok{ qnorm, }\AttributeTok{dparams =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ mean\_pH, }\AttributeTok{sd =}\NormalTok{ sd\_pH)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical probabilities"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical probabilities"}
\NormalTok{  )  }
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  good wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pp\_good }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(good\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{(}\AttributeTok{distribution =}\NormalTok{ qnorm, }\AttributeTok{dparams =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ mean\_pH\_good, }\AttributeTok{sd =}\NormalTok{ sd\_pH\_good)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{distribution =}\NormalTok{ qnorm, }\AttributeTok{dparams =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ mean\_pH\_good, }\AttributeTok{sd =}\NormalTok{ sd\_pH\_good)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical probabilities"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical probabilities"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  bad wines
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pp\_bad }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(bad\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ pH)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{(}\AttributeTok{distribution =}\NormalTok{ qnorm, }\AttributeTok{dparams =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ mean\_pH\_bad, }\AttributeTok{sd =}\NormalTok{ sd\_pH\_bad)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{distribution =}\NormalTok{ qnorm, }\AttributeTok{dparams =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ mean\_pH\_bad, }\AttributeTok{sd =}\NormalTok{ sd\_pH\_bad)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical probabilities"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical probabilities"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggarrange}\NormalTok{(pp\_all, pp\_good, pp\_bad, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"all"}\NormalTok{, }\StringTok{"good"}\NormalTok{, }\StringTok{"bad"}\NormalTok{), }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-28-1.pdf}}

Samples probably do not follow normal distribution, as tails of QQ and
PP plots do not lay on the line.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  empirical distribution function + confidence intervals
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate confidence bands}

\NormalTok{bands }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, analysed\_variable, alpha) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{analysed\_variable)}
\NormalTok{  mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{analysed\_variable)}
\NormalTok{  sd }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{analysed\_variable)}
\NormalTok{  z\_alpha }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alpha }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{  lower }\OtherTok{\textless{}{-}}\NormalTok{ mean }\SpecialCharTok{{-}}\NormalTok{ z\_alpha }\SpecialCharTok{*}\NormalTok{ sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}
\NormalTok{  upper }\OtherTok{\textless{}{-}}\NormalTok{ mean }\SpecialCharTok{+}\NormalTok{ z\_alpha }\SpecialCharTok{*}\NormalTok{ sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}
  \FunctionTok{data.frame}\NormalTok{(lower, upper)}
\NormalTok{\}}

\NormalTok{alpha }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{all\_bands }\OtherTok{\textless{}{-}} \FunctionTok{bands}\NormalTok{(wine, analysed\_variable, alpha)}
\NormalTok{good\_bands }\OtherTok{\textless{}{-}} \FunctionTok{bands}\NormalTok{(good\_wine, analysed\_variable, alpha)}
\NormalTok{bad\_bands }\OtherTok{\textless{}{-}} \FunctionTok{bands}\NormalTok{(bad\_wine, analysed\_variable, alpha)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable), }\AttributeTok{color =} \StringTok{"\#6a6ad9"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ all\_bands}\SpecialCharTok{$}\NormalTok{lower, }\AttributeTok{color =} \StringTok{"\#6a6ad9"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ all\_bands}\SpecialCharTok{$}\NormalTok{upper, }\AttributeTok{color =} \StringTok{"\#6a6ad9"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ good\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable), }\AttributeTok{color =} \StringTok{"\#6dcc6b"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ good\_bands}\SpecialCharTok{$}\NormalTok{lower, }\AttributeTok{color =} \StringTok{"\#6dcc6b"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ good\_bands}\SpecialCharTok{$}\NormalTok{upper, }\AttributeTok{color =} \StringTok{"\#6dcc6b"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{data =}\NormalTok{ bad\_wine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ analysed\_variable), }\AttributeTok{color =} \StringTok{"\#b37d69"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ bad\_bands}\SpecialCharTok{$}\NormalTok{lower, }\AttributeTok{color =} \StringTok{"\#b37d69"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ bad\_bands}\SpecialCharTok{$}\NormalTok{upper, }\AttributeTok{color =} \StringTok{"\#b37d69"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-30-1.pdf}}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\item
  EDF + uniform confidence bands
\item
  EDFs for good and bad wines
\end{enumerate}

\subsubsection{Exercise 3}\label{exercise-3}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  MLE for mu
\end{enumerate}

\[
f(x; \mu, \sigma) = \frac{1}{2\sigma} \exp \left( -\frac{|x - \mu|}{\sigma} \right)
\]

The log-likelihood function:

\[
\ell(\mu, \sigma) = \sum_{i=1}^n \log \left( \frac{1}{2\sigma} \exp \left( -\frac{|X_i - \mu|}{\sigma} \right) \right) =
\]

\[
= \ell(\mu, \sigma) = -n \log(2\sigma) - \frac{1}{\sigma} \sum_{i=1}^n |X_i - \mu|
\]

To find MLE for \(\mu\), we need to maximize \(\ell(\mu, \sigma)\) with
respect to \(\mu\) This is equivalent to minimizing the sum of absolute
deviations:

\[
\text{minimize} \sum_{i=1}^n |X_i - \mu|
\]

According to statistics, the sum of absolute deviations is minimal at
the median

Having n even gives us two equally good estimators, but when number of
observations is odd, the estimator will be unique.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  quantile
\end{enumerate}

\begin{itemize}
\tightlist
\item
  for 20 observations
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{999}\NormalTok{)}

\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sample\_20 }\OtherTok{\textless{}{-}} \FunctionTok{rlaplace}\NormalTok{(n, mu, sigma)}

\NormalTok{real\_median\_20 }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(sample\_20)}

\NormalTok{mle\_quantile\_20 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{diff\_quantile\_20 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{(type }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{) \{}
\NormalTok{  mle\_quantile\_20[type] }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(sample\_20, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{type =}\NormalTok{ type)}
\NormalTok{  diff\_quantile\_20[type] }\OtherTok{\textless{}{-}}\NormalTok{ mle\_quantile\_20[type] }\SpecialCharTok{{-}}\NormalTok{ real\_median\_20}
\NormalTok{\}}

\NormalTok{diff\_quantile\_20}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.01284831  0.00000000 -0.01284831 -0.01284831  0.00000000  0.00000000
## [7]  0.00000000  0.00000000  0.00000000
\end{verbatim}

So, types 2, 5, 6, 7, 8, 9 of function quantile predict better than 1, 3
and 4 types Here, the choice of quantile type significantly affects the
result because this sample may not be representative due to small number
of observations

\begin{itemize}
\tightlist
\item
  for 1000 observations
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{999}\NormalTok{)}

\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sample\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{rlaplace}\NormalTok{(n, mu, sigma)}

\NormalTok{real\_median\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(sample\_1000)}

\NormalTok{mle\_quantile\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{diff\_quantile\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{(type }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{) \{}
\NormalTok{  mle\_quantile\_1000[type] }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(sample\_1000, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{type =}\NormalTok{ type)}
\NormalTok{  diff\_quantile\_1000[type] }\OtherTok{\textless{}{-}}\NormalTok{ mle\_quantile\_1000[type] }\SpecialCharTok{{-}}\NormalTok{ real\_median\_1000}
\NormalTok{\}}

\NormalTok{diff\_quantile\_1000}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.0001569595  0.0000000000 -0.0001569595 -0.0001569595  0.0000000000
## [6]  0.0000000000  0.0000000000  0.0000000000  0.0000000000
\end{verbatim}

For 1000 observations the best predictors are 2, 5, 6-9 types of fn
quantile, similar as for 20 observations. It is noticable that the
difference for other types of quantile fn is much smaller than for 20
observations, which means that increasing the number of observations
estimator gets more confident and shows better results Looks like we
just proved the law of large numbers :)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  MLE function
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mle\_optimise }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  log\_lik\_laplace }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(mu, data) \{}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(data }\SpecialCharTok{{-}}\NormalTok{ mu))) }\CommentTok{\# from calculations in a}
\NormalTok{  \}}
\NormalTok{  result }\OtherTok{\textless{}{-}} \FunctionTok{optimise}\NormalTok{(}
\NormalTok{    log\_lik\_laplace,}
    \AttributeTok{interval =} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(data), }\FunctionTok{max}\NormalTok{(data)),}
    \AttributeTok{data =}\NormalTok{ data)}
  \FunctionTok{return}\NormalTok{(result}\SpecialCharTok{$}\NormalTok{minimum)}
\NormalTok{\}}

\NormalTok{mle\_optimise\_20 }\OtherTok{\textless{}{-}} \FunctionTok{mle\_optimise}\NormalTok{(sample\_20)}
\NormalTok{mle\_quantile\_20 }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(sample\_20, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{type =} \DecValTok{2}\NormalTok{) }\CommentTok{\# taking second as one of the best types}

\NormalTok{mle\_optimise\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{mle\_optimise}\NormalTok{(sample\_1000)}
\NormalTok{mle\_quantile\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(sample\_1000, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{type =} \DecValTok{2}\NormalTok{)}

\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{optimise =} \FunctionTok{c}\NormalTok{(mle\_optimise\_20, mle\_optimise\_1000),}
  \AttributeTok{quantile =} \FunctionTok{c}\NormalTok{(mle\_quantile\_20, mle\_quantile\_1000),}
  \AttributeTok{real =} \FunctionTok{c}\NormalTok{(real\_median\_20, real\_median\_1000),}
  \AttributeTok{row.names =} \FunctionTok{c}\NormalTok{(}\StringTok{"20"}\NormalTok{, }\StringTok{"1000"}\NormalTok{)}
\NormalTok{)}
\FunctionTok{print}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      optimise quantile     real
## 20   1.066128 1.067329 1.067329
## 1000 1.028546 1.028643 1.028643
\end{verbatim}

Function `optimise' uses a combination of golden section search and
successive parabolic interpolation to find the minimum or maximum in the
selected interval. Golden section search uses golden ratio to narrow the
range of values that potentially can be the extremums, while successive
parabolic interpolation fits a quadratic function through three points,
then the vertex is used for new fitting and so on.

The Newton-Raphson method is not suitable for Laplace function, as it
requires continuously differentable function, but Laplace one is not
smooth at the point \(\mu = X_i\)

Talking about the results, quantile estimates better, because, as I
understood, it simply takes the median, knowing that it's a best
estimator However, optimise function also gives a pretty close estimate
especially when increasing the sample size.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  MLE distribution
\end{enumerate}

\begin{itemize}
\tightlist
\item
  sample size = 20
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1000}\NormalTok{)}

\NormalTok{n }\OtherTok{=} \DecValTok{20} \CommentTok{\# sample size}
\NormalTok{m }\OtherTok{=} \DecValTok{5000} \CommentTok{\# num of MLEs}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{mle\_generator }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{m) \{}
\NormalTok{  mle\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rlaplace}\NormalTok{(n, mu, sigma)}
\NormalTok{  mle\_generator[i] }\OtherTok{\textless{}{-}} \FunctionTok{mle\_optimise}\NormalTok{(mle\_sample)}
\NormalTok{\}}

\NormalTok{mle\_df\_20 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(mle\_generator)}
\FunctionTok{head}\NormalTok{(mle\_df\_20)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   mle_generator
## 1     1.4299422
## 2     0.9766319
## 3     1.2763803
## 4     1.3678812
## 5     0.8346567
## 6     1.2527940
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mle\_df\_20, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mle\_generator)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#6dcc6b"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"MLEs"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"MLEs for sample size = 20"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-34-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mle\_df\_20, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ mle\_generator)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-34-2.pdf}}

\begin{itemize}
\tightlist
\item
  sample size = 1000
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1000}\NormalTok{)}

\NormalTok{n }\OtherTok{=} \DecValTok{1000} \CommentTok{\# sample size}
\NormalTok{m }\OtherTok{=} \DecValTok{5000} \CommentTok{\# num of MLEs}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{mle\_generator }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{m) \{}
\NormalTok{  mle\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rlaplace}\NormalTok{(n, mu, sigma)}
\NormalTok{  mle\_generator[i] }\OtherTok{\textless{}{-}} \FunctionTok{mle\_optimise}\NormalTok{(mle\_sample)}
\NormalTok{\}}

\NormalTok{mle\_df\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(mle\_generator)}
\FunctionTok{head}\NormalTok{(mle\_df\_1000)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   mle_generator
## 1     0.9860654
## 2     1.0242332
## 3     0.9770321
## 4     0.9992078
## 5     0.9645295
## 6     0.9656646
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mle\_df\_1000, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mle\_generator)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#6ba4cc"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"MLEs"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"count"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"MLEs for sample size = 20"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-35-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mle\_df\_1000, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ mle\_generator)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-35-2.pdf}}

For samples of size 20 estimators visually followed the normal
distribution, but QQ plot showed that it is skewed a little But,
increasing the sample size to 1000 produced perfect normal distribution,
giving us the representation of the central limit theorem.

\begin{itemize}
\tightlist
\item
  variances
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(mle\_df\_20)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               mle_generator
## mle_generator    0.06470342
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(mle\_df\_1000)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               mle_generator
## mle_generator   0.001056158
\end{verbatim}

Increasing the sample size also highly decreases the variance,
therefore, increases our confidence in predicting the true parameter.

\subsubsection{Exercise 4}\label{exercise-4}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{house }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"kc\_house\_data.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(price, bedrooms, bathrooms,}
\NormalTok{  sqft\_living, floors, view,}
\NormalTok{  condition, grade, yr\_built)}

\FunctionTok{head}\NormalTok{(house)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     price bedrooms bathrooms sqft_living floors view condition grade yr_built
## 1  221900        3      1.00        1180      1    0         3     7     1955
## 2  538000        3      2.25        2570      2    0         3     7     1951
## 3  180000        2      1.00         770      1    0         3     6     1933
## 4  604000        4      3.00        1960      1    0         5     7     1965
## 5  510000        3      2.00        1680      1    0         3     8     1987
## 6 1225000        4      4.50        5420      1    0         3    11     2001
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(house)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      price            bedrooms        bathrooms      sqft_living   
##  Min.   :  75000   Min.   : 0.000   Min.   :0.000   Min.   :  290  
##  1st Qu.: 321950   1st Qu.: 3.000   1st Qu.:1.750   1st Qu.: 1427  
##  Median : 450000   Median : 3.000   Median :2.250   Median : 1910  
##  Mean   : 540088   Mean   : 3.371   Mean   :2.115   Mean   : 2080  
##  3rd Qu.: 645000   3rd Qu.: 4.000   3rd Qu.:2.500   3rd Qu.: 2550  
##  Max.   :7700000   Max.   :33.000   Max.   :8.000   Max.   :13540  
##      floors           view          condition         grade       
##  Min.   :1.000   Min.   :0.0000   Min.   :1.000   Min.   : 1.000  
##  1st Qu.:1.000   1st Qu.:0.0000   1st Qu.:3.000   1st Qu.: 7.000  
##  Median :1.500   Median :0.0000   Median :3.000   Median : 7.000  
##  Mean   :1.494   Mean   :0.2343   Mean   :3.409   Mean   : 7.657  
##  3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.:4.000   3rd Qu.: 8.000  
##  Max.   :3.500   Max.   :4.0000   Max.   :5.000   Max.   :13.000  
##     yr_built   
##  Min.   :1900  
##  1st Qu.:1951  
##  Median :1975  
##  Mean   :1971  
##  3rd Qu.:1997  
##  Max.   :2015
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  linear model for price
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_price }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(price }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bedrooms }\SpecialCharTok{+}\NormalTok{ bathrooms }\SpecialCharTok{+}\NormalTok{ sqft\_living }\SpecialCharTok{+}
\NormalTok{  floors }\SpecialCharTok{+}\NormalTok{ view }\SpecialCharTok{+}\NormalTok{ condition }\SpecialCharTok{+}\NormalTok{ grade }\SpecialCharTok{+}\NormalTok{ yr\_built,}
  \AttributeTok{data =}\NormalTok{ house)}

\FunctionTok{summary}\NormalTok{(model\_price)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = price ~ bedrooms + bathrooms + sqft_living + floors + 
##     view + condition + grade + yr_built, data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1337280  -111873   -10359    90133  4470268 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  6.356e+06  1.326e+05  47.950  < 2e-16 ***
## bedrooms    -4.065e+04  2.066e+03 -19.671  < 2e-16 ***
## bathrooms    4.769e+04  3.487e+03  13.677  < 2e-16 ***
## sqft_living  1.693e+02  3.307e+00  51.199  < 2e-16 ***
## floors       2.832e+04  3.496e+03   8.101 5.72e-16 ***
## view         7.138e+04  2.107e+03  33.885  < 2e-16 ***
## condition    1.815e+04  2.519e+03   7.205 6.01e-13 ***
## grade        1.228e+05  2.187e+03  56.160  < 2e-16 ***
## yr_built    -3.650e+03  6.824e+01 -53.484  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 221600 on 21604 degrees of freedom
## Multiple R-squared:  0.6359, Adjusted R-squared:  0.6358 
## F-statistic:  4717 on 8 and 21604 DF,  p-value: < 2.2e-16
\end{verbatim}

All variables are significant, \(R^2\) equals to 0.6359 which means that
\textasciitilde{} 64\% of variance in the price is explained by those
variables

\begin{itemize}
\tightlist
\item
  residual analysis
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# residuals vs fitted}
\NormalTok{res\_fit }\OtherTok{\textless{}{-}} \FunctionTok{plot}\NormalTok{(model\_price, }\AttributeTok{which=}\DecValTok{1}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-39-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# q{-}q plot}
\NormalTok{qq }\OtherTok{\textless{}{-}} \FunctionTok{plot}\NormalTok{(model\_price, }\AttributeTok{which=}\DecValTok{2}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-39-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scale{-}location}
\NormalTok{scale }\OtherTok{\textless{}{-}} \FunctionTok{plot}\NormalTok{(model\_price, }\AttributeTok{which=}\DecValTok{3}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"pink"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-39-3.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggarrange}\NormalTok{(res\_fit, qq, scale, }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-40-1.pdf}}

Residuals are not normally distributed and their variance is not the
same, which means that our model violates normality and homoskedasticity
of errors assumptions.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  price vs log(price)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  histograms
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{price\_hist }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#6a6ad9"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{log\_price }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(house}\SpecialCharTok{$}\NormalTok{price)}

\NormalTok{log\_price\_hist }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{100}\NormalTok{, }\AttributeTok{fill=}\StringTok{"\#6a6ad9"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggarrange}\NormalTok{(price\_hist, log\_price\_hist, }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-42-1.pdf}}

\begin{itemize}
\tightlist
\item
  QQ plots
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qq\_price }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ price)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}

\NormalTok{qq\_log\_price }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggarrange}\NormalTok{(qq\_price, qq\_log\_price, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"price"}\NormalTok{, }\StringTok{"log\_price"}\NormalTok{), }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-44-1.pdf}}

Log(price) looks closer to the normal distribution that price.

\begin{itemize}
\tightlist
\item
  model fit
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_log\_price }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(price) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bedrooms }\SpecialCharTok{+}\NormalTok{ bathrooms }\SpecialCharTok{+}\NormalTok{ sqft\_living }\SpecialCharTok{+}
\NormalTok{  floors }\SpecialCharTok{+}\NormalTok{ view }\SpecialCharTok{+}\NormalTok{ condition }\SpecialCharTok{+}\NormalTok{ grade }\SpecialCharTok{+}\NormalTok{ yr\_built,}
  \AttributeTok{data =}\NormalTok{ house)}

\FunctionTok{summary}\NormalTok{(model\_log\_price)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = log(price) ~ bedrooms + bathrooms + sqft_living + 
##     floors + view + condition + grade + yr_built, data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.90374 -0.21157  0.01624  0.21288  1.38880 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  2.151e+01  1.884e-01 114.155  < 2e-16 ***
## bedrooms    -2.366e-02  2.937e-03  -8.056 8.28e-16 ***
## bathrooms    8.500e-02  4.956e-03  17.152  < 2e-16 ***
## sqft_living  1.664e-04  4.701e-06  35.402  < 2e-16 ***
## floors       8.569e-02  4.968e-03  17.246  < 2e-16 ***
## view         6.740e-02  2.994e-03  22.510  < 2e-16 ***
## condition    4.226e-02  3.580e-03  11.803  < 2e-16 ***
## grade        2.218e-01  3.108e-03  71.359  < 2e-16 ***
## yr_built    -5.526e-03  9.699e-05 -56.980  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3149 on 21604 degrees of freedom
## Multiple R-squared:  0.6426, Adjusted R-squared:  0.6425 
## F-statistic:  4856 on 8 and 21604 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# residuals vs fitted}
\FunctionTok{plot}\NormalTok{(model\_log\_price, }\AttributeTok{which=}\DecValTok{1}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-45-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# q{-}q plot}
\FunctionTok{plot}\NormalTok{(model\_log\_price, }\AttributeTok{which=}\DecValTok{2}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-45-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scale{-}location}
\FunctionTok{plot}\NormalTok{(model\_log\_price, }\AttributeTok{which=}\DecValTok{3}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"pink"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-45-3.pdf}}

After changing price to log(price), all variables are still significant,
R\^{}2 is also around 64\%, which means that predictive quality of the
model didn't decrease Additionally, residuals look much better - they
are normally distributed and variance seems constant for all values By
looking at the covariates we can see the the percentage effect of each,
which is much more convenient for further analysis than looking at
absolute change.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  effect of covariates
\end{enumerate}

\begin{itemize}
\tightlist
\item
  intercept: expected value of log(price) is \textasciitilde{} 21.51
  when all other parameters are zero
\item
  bedrooms: each additional bedroom decreases the price by
  \textasciitilde{} 2.34\% This, actually, doesn't make sense, by
  looking at the graph below, seems that the one outlier changes the
  sign of the coefficient, model fit, however, it should be positive.
\item
  bathrooms: each additional bathroom increases the price by
  \textasciitilde{} 8.5\%
\item
  sqft\_living: each additional square foot of living area increases the
  price by \textasciitilde{} 0.0166\%
\item
  floors: each additional floor in the house increases the price by
  \textasciitilde{} 8.57\%
\item
  view: each additional view increases the price by \textasciitilde{}
  6.74\%
\item
  condition: each additional unit of condition rating increases the
  price by \textasciitilde{} 4.23\%
\item
  grade: each additional grade increases the price by \textasciitilde{}
  22.18\%
\item
  yr\_built: each additional year when house was built decreases the
  price by \textasciitilde{} 0.55\%
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bedrooms }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bedrooms, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{bathrooms }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bathrooms, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{sqft }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sqft\_living, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{floors }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ floors, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{views }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ view, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{condition }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ condition, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{grade }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grade, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{yr\_built }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(house, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ yr\_built, }\AttributeTok{y =}\NormalTok{ log\_price)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggarrange}\NormalTok{(bedrooms, bathrooms, sqft, floors, views, condition, grade, yr\_built,}
  \AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-47-1.pdf}}

\begin{itemize}
\tightlist
\item
  adding squares
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_log\_price\_sq }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(price) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bedrooms }\SpecialCharTok{+}\NormalTok{ bathrooms }\SpecialCharTok{+}\NormalTok{ sqft\_living  }\SpecialCharTok{+}
\NormalTok{  floors }\SpecialCharTok{+}\NormalTok{ view }\SpecialCharTok{+}\NormalTok{ condition }\SpecialCharTok{+}\NormalTok{ grade }\SpecialCharTok{+}\NormalTok{ yr\_built }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(sqft\_living}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(yr\_built}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
  \AttributeTok{data =}\NormalTok{ house)}

\FunctionTok{summary}\NormalTok{(model\_log\_price\_sq)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = log(price) ~ bedrooms + bathrooms + sqft_living + 
##     floors + view + condition + grade + yr_built + I(sqft_living^2) + 
##     I(yr_built^2), data = house)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.2644 -0.2113  0.0138  0.2107  1.4160 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       1.674e+02  1.082e+01  15.470   <2e-16 ***
## bedrooms         -2.978e-02  3.009e-03  -9.895   <2e-16 ***
## bathrooms         7.317e-02  4.959e-03  14.754   <2e-16 ***
## sqft_living       2.792e-04  8.690e-06  32.132   <2e-16 ***
## floors            4.733e-02  5.613e-03   8.432   <2e-16 ***
## view              7.222e-02  2.979e-03  24.247   <2e-16 ***
## condition         4.640e-02  3.591e-03  12.920   <2e-16 ***
## grade             2.176e-01  3.092e-03  70.355   <2e-16 ***
## yr_built         -1.545e-01  1.106e-02 -13.978   <2e-16 ***
## I(sqft_living^2) -1.782e-08  1.172e-09 -15.212   <2e-16 ***
## I(yr_built^2)     3.802e-05  2.823e-06  13.468   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.312 on 21602 degrees of freedom
## Multiple R-squared:  0.6492, Adjusted R-squared:  0.649 
## F-statistic:  3998 on 10 and 21602 DF,  p-value: < 2.2e-16
\end{verbatim}

Adding squares (which are significant predictors) slightly improves the
model fit (0.6492 R\^{}2 compared to 0.6426)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  prediction
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1122}\NormalTok{)}
\NormalTok{sample\_size }\OtherTok{\textless{}{-}} \DecValTok{10806}
\NormalTok{train\_indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(house), sample\_size)}
\NormalTok{house\_train }\OtherTok{\textless{}{-}}\NormalTok{ house[train\_indices, ]}
\NormalTok{house\_test }\OtherTok{\textless{}{-}}\NormalTok{ house[}\SpecialCharTok{{-}}\NormalTok{train\_indices, ]}
\FunctionTok{summary}\NormalTok{(house\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      price            bedrooms        bathrooms      sqft_living   
##  Min.   :  78000   Min.   : 0.000   Min.   :0.000   Min.   :  380  
##  1st Qu.: 320000   1st Qu.: 3.000   1st Qu.:1.500   1st Qu.: 1420  
##  Median : 450000   Median : 3.000   Median :2.250   Median : 1900  
##  Mean   : 537698   Mean   : 3.365   Mean   :2.106   Mean   : 2073  
##  3rd Qu.: 642000   3rd Qu.: 4.000   3rd Qu.:2.500   3rd Qu.: 2538  
##  Max.   :7700000   Max.   :10.000   Max.   :8.000   Max.   :13540  
##      floors          view          condition         grade       
##  Min.   :1.00   Min.   :0.0000   Min.   :1.000   Min.   : 3.000  
##  1st Qu.:1.00   1st Qu.:0.0000   1st Qu.:3.000   1st Qu.: 7.000  
##  Median :1.50   Median :0.0000   Median :3.000   Median : 7.000  
##  Mean   :1.49   Mean   :0.2369   Mean   :3.415   Mean   : 7.646  
##  3rd Qu.:2.00   3rd Qu.:0.0000   3rd Qu.:4.000   3rd Qu.: 8.000  
##  Max.   :3.50   Max.   :4.0000   Max.   :5.000   Max.   :13.000  
##     yr_built   
##  Min.   :1900  
##  1st Qu.:1951  
##  Median :1974  
##  Mean   :1971  
##  3rd Qu.:1996  
##  Max.   :2015
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(house\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      price            bedrooms        bathrooms      sqft_living   
##  Min.   :  75000   Min.   : 0.000   Min.   :0.000   Min.   :  290  
##  1st Qu.: 325000   1st Qu.: 3.000   1st Qu.:1.750   1st Qu.: 1430  
##  Median : 451000   Median : 3.000   Median :2.250   Median : 1920  
##  Mean   : 542478   Mean   : 3.376   Mean   :2.123   Mean   : 2086  
##  3rd Qu.: 645000   3rd Qu.: 4.000   3rd Qu.:2.500   3rd Qu.: 2560  
##  Max.   :7062500   Max.   :33.000   Max.   :7.750   Max.   :10040  
##      floors           view          condition         grade       
##  Min.   :1.000   Min.   :0.0000   Min.   :1.000   Min.   : 1.000  
##  1st Qu.:1.000   1st Qu.:0.0000   1st Qu.:3.000   1st Qu.: 7.000  
##  Median :1.500   Median :0.0000   Median :3.000   Median : 7.000  
##  Mean   :1.499   Mean   :0.2317   Mean   :3.403   Mean   : 7.668  
##  3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.:4.000   3rd Qu.: 8.000  
##  Max.   :3.500   Max.   :4.0000   Max.   :5.000   Max.   :13.000  
##     yr_built   
##  Min.   :1900  
##  1st Qu.:1952  
##  Median :1975  
##  Mean   :1971  
##  3rd Qu.:1997  
##  Max.   :2015
\end{verbatim}

\begin{itemize}
\tightlist
\item
  models b and c on training dataset
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model b}
\NormalTok{model\_log\_price }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(price) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bedrooms }\SpecialCharTok{+}\NormalTok{ bathrooms }\SpecialCharTok{+}\NormalTok{ sqft\_living }\SpecialCharTok{+}
\NormalTok{  floors }\SpecialCharTok{+}\NormalTok{ view }\SpecialCharTok{+}\NormalTok{ condition }\SpecialCharTok{+}\NormalTok{ grade }\SpecialCharTok{+}\NormalTok{ yr\_built,}
  \AttributeTok{data =}\NormalTok{ house\_train)}

\CommentTok{\# model c}
\NormalTok{model\_log\_price\_sq }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(price) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bedrooms }\SpecialCharTok{+}\NormalTok{ bathrooms }\SpecialCharTok{+}\NormalTok{ sqft\_living  }\SpecialCharTok{+}
\NormalTok{  floors }\SpecialCharTok{+}\NormalTok{ view }\SpecialCharTok{+}\NormalTok{ condition }\SpecialCharTok{+}\NormalTok{ grade }\SpecialCharTok{+}\NormalTok{ yr\_built }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(sqft\_living}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(yr\_built}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
  \AttributeTok{data =}\NormalTok{ house\_train)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  predictions on test dataset
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# predictions}
\NormalTok{pred\_log\_price }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_log\_price, }\AttributeTok{newdata =}\NormalTok{ house\_test)}
\NormalTok{pred\_log\_price\_sq }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_log\_price\_sq, }\AttributeTok{newdata =}\NormalTok{ house\_test)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  MSE for both models
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mse\_log\_price }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((}\FunctionTok{log}\NormalTok{(house\_test}\SpecialCharTok{$}\NormalTok{price) }\SpecialCharTok{{-}}\NormalTok{ pred\_log\_price)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mse\_log\_price\_sq }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((}\FunctionTok{log}\NormalTok{(house\_test}\SpecialCharTok{$}\NormalTok{price) }\SpecialCharTok{{-}}\NormalTok{ pred\_log\_price\_sq)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mse\_log\_price}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09773623
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mse\_log\_price\_sq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09654389
\end{verbatim}

The second model gives a better prediction, as MSE there is smaller
Let's improve the model by: 1. removing outlier with 33 bedrooms in
training dataset 2. adding interaction bedrooms\emph{bathrooms as they
are correlated (bathrooms means bathroom per bedroom) 3. adding
interaction condition}grade as they also seem correlated

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{house\_clean\_train }\OtherTok{\textless{}{-}}\NormalTok{ house\_train }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(bedrooms }\SpecialCharTok{\textless{}} \DecValTok{33}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_log\_sqft }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(price) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ bedrooms }\SpecialCharTok{+}\NormalTok{ bathrooms }\SpecialCharTok{+}\NormalTok{ sqft\_living }\SpecialCharTok{+}
\NormalTok{  floors }\SpecialCharTok{+}\NormalTok{ view }\SpecialCharTok{+}\NormalTok{ condition }\SpecialCharTok{+}\NormalTok{ grade }\SpecialCharTok{+}\NormalTok{ yr\_built }\SpecialCharTok{+}
  \FunctionTok{I}\NormalTok{(sqft\_living}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(yr\_built}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  bedrooms}\SpecialCharTok{*}\NormalTok{bathrooms }\SpecialCharTok{+}\NormalTok{ condition}\SpecialCharTok{*}\NormalTok{grade,}
  \AttributeTok{data =}\NormalTok{ house\_clean\_train)}

\NormalTok{pred\_log\_sqft }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(model\_log\_sqft, }\AttributeTok{newdata =}\NormalTok{ house\_test)}
\FunctionTok{mean}\NormalTok{((}\FunctionTok{log}\NormalTok{(house\_test}\SpecialCharTok{$}\NormalTok{price) }\SpecialCharTok{{-}}\NormalTok{ pred\_log\_sqft)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# new}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09646216
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mse\_log\_price\_sq }\CommentTok{\# old}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09654389
\end{verbatim}

MSE in this case is a bit smaller which means that the new model
predicts better, however, it still can be a random effect

\subsubsection{Exercise 5}\label{exercise-5}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  loading data
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hitters }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Hitters.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{na.omit}\NormalTok{()}

\FunctionTok{head}\NormalTok{(hitters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks
## 2   315   81     7   24  38    39    14   3449   835     69   321  414    375
## 3   479  130    18   66  72    76     3   1624   457     63   224  266    263
## 4   496  141    20   65  78    37    11   5628  1575    225   828  838    354
## 5   321   87    10   39  42    30     2    396   101     12    48   46     33
## 6   594  169     4   74  51    35    11   4408  1133     19   501  336    194
## 7   185   37     1   23   8    21     2    214    42      1    30    9     24
##   League Division PutOuts Assists Errors Salary NewLeague
## 2      N        W     632      43     10  475.0         N
## 3      A        W     880      82     14  480.0         A
## 4      N        E     200      11      3  500.0         N
## 5      N        E     805      40      4   91.5         N
## 6      A        W     282     421     25  750.0         A
## 7      N        E      76     127      7   70.0         A
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(hitters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      AtBat            Hits           HmRun            Runs       
##  Min.   : 19.0   Min.   :  1.0   Min.   : 0.00   Min.   :  0.00  
##  1st Qu.:282.5   1st Qu.: 71.5   1st Qu.: 5.00   1st Qu.: 33.50  
##  Median :413.0   Median :103.0   Median : 9.00   Median : 52.00  
##  Mean   :403.6   Mean   :107.8   Mean   :11.62   Mean   : 54.75  
##  3rd Qu.:526.0   3rd Qu.:141.5   3rd Qu.:18.00   3rd Qu.: 73.00  
##  Max.   :687.0   Max.   :238.0   Max.   :40.00   Max.   :130.00  
##       RBI             Walks            Years            CAtBat       
##  Min.   :  0.00   Min.   :  0.00   Min.   : 1.000   Min.   :   19.0  
##  1st Qu.: 30.00   1st Qu.: 23.00   1st Qu.: 4.000   1st Qu.:  842.5  
##  Median : 47.00   Median : 37.00   Median : 6.000   Median : 1931.0  
##  Mean   : 51.49   Mean   : 41.11   Mean   : 7.312   Mean   : 2657.5  
##  3rd Qu.: 71.00   3rd Qu.: 57.00   3rd Qu.:10.000   3rd Qu.: 3890.5  
##  Max.   :121.00   Max.   :105.00   Max.   :24.000   Max.   :14053.0  
##      CHits            CHmRun           CRuns             CRBI       
##  Min.   :   4.0   Min.   :  0.00   Min.   :   2.0   Min.   :   3.0  
##  1st Qu.: 212.0   1st Qu.: 15.00   1st Qu.: 105.5   1st Qu.:  95.0  
##  Median : 516.0   Median : 40.00   Median : 250.0   Median : 230.0  
##  Mean   : 722.2   Mean   : 69.24   Mean   : 361.2   Mean   : 330.4  
##  3rd Qu.:1054.0   3rd Qu.: 92.50   3rd Qu.: 497.5   3rd Qu.: 424.5  
##  Max.   :4256.0   Max.   :548.00   Max.   :2165.0   Max.   :1659.0  
##      CWalks          League            Division            PutOuts      
##  Min.   :   1.0   Length:263         Length:263         Min.   :   0.0  
##  1st Qu.:  71.0   Class :character   Class :character   1st Qu.: 113.5  
##  Median : 174.0   Mode  :character   Mode  :character   Median : 224.0  
##  Mean   : 260.3                                         Mean   : 290.7  
##  3rd Qu.: 328.5                                         3rd Qu.: 322.5  
##  Max.   :1566.0                                         Max.   :1377.0  
##     Assists          Errors           Salary        NewLeague        
##  Min.   :  0.0   Min.   : 0.000   Min.   :  67.5   Length:263        
##  1st Qu.:  8.0   1st Qu.: 3.000   1st Qu.: 190.0   Class :character  
##  Median : 45.0   Median : 7.000   Median : 425.0   Mode  :character  
##  Mean   :118.8   Mean   : 8.593   Mean   : 535.9                     
##  3rd Qu.:192.0   3rd Qu.:13.000   3rd Qu.: 750.0                     
##  Max.   :492.0   Max.   :32.000   Max.   :2460.0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  condition number
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ hitters}\SpecialCharTok{$}\NormalTok{Salary}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ hitters }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Salary)}

\CommentTok{\# create matrix and replace categorical variables with columns 1 or 0}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ X) }\CommentTok{\# {-}1 for removing intercept}
\FunctionTok{head}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks
## 2   315   81     7   24  38    39    14   3449   835     69   321  414    375
## 3   479  130    18   66  72    76     3   1624   457     63   224  266    263
## 4   496  141    20   65  78    37    11   5628  1575    225   828  838    354
## 5   321   87    10   39  42    30     2    396   101     12    48   46     33
## 6   594  169     4   74  51    35    11   4408  1133     19   501  336    194
## 7   185   37     1   23   8    21     2    214    42      1    30    9     24
##   LeagueA LeagueN DivisionW PutOuts Assists Errors NewLeagueN
## 2       0       1         1     632      43     10          1
## 3       1       0         1     880      82     14          0
## 4       0       1         0     200      11      3          1
## 5       0       1         0     805      40      4          1
## 6       1       0         1     282     421     25          0
## 7       0       1         0      76     127      7          0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XtX }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X}

\NormalTok{eigenvalues }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(XtX)}\SpecialCharTok{$}\NormalTok{values}

\NormalTok{condition\_number }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(eigenvalues) }\SpecialCharTok{/} \FunctionTok{min}\NormalTok{(eigenvalues)}
\NormalTok{condition\_number}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 703904352
\end{verbatim}

The condition number is very high, which shows that there is a high
multicollinearity among some variables

\begin{itemize}
\tightlist
\item
  standardization
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_stand }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(X)}

\NormalTok{XtX\_stand }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(X\_stand) }\SpecialCharTok{\%*\%}\NormalTok{ X\_stand}

\NormalTok{eigenvalues\_stand }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(XtX\_stand)}\SpecialCharTok{$}\NormalTok{values}

\NormalTok{condition\_number\_stand }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(eigenvalues\_stand) }\SpecialCharTok{/} \FunctionTok{min}\NormalTok{(eigenvalues\_stand)}
\NormalTok{condition\_number\_stand}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.980008e+16
\end{verbatim}

Standardization didn't help, we even onbtained much higher number
because there is a very small eigenvalue 2.131628e-14

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  models
\end{enumerate}

\begin{itemize}
\tightlist
\item
  standard linear model
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_hitters }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X)}
\FunctionTok{summary}\NormalTok{(lm\_hitters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -907.62 -178.35  -31.11  139.09 1877.04 
## 
## Coefficients: (1 not defined because of singularities)
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  225.70301  109.89206   2.054 0.041059 *  
## XAtBat        -1.97987    0.63398  -3.123 0.002008 ** 
## XHits          7.50077    2.37753   3.155 0.001808 ** 
## XHmRun         4.33088    6.20145   0.698 0.485616    
## XRuns         -2.37621    2.98076  -0.797 0.426122    
## XRBI          -1.04496    2.60088  -0.402 0.688204    
## XWalks         6.23129    1.82850   3.408 0.000766 ***
## XYears        -3.48905   12.41219  -0.281 0.778874    
## XCAtBat       -0.17134    0.13524  -1.267 0.206380    
## XCHits         0.13399    0.67455   0.199 0.842713    
## XCHmRun       -0.17286    1.61724  -0.107 0.914967    
## XCRuns         1.45430    0.75046   1.938 0.053795 .  
## XCRBI          0.80771    0.69262   1.166 0.244691    
## XCWalks       -0.81157    0.32808  -2.474 0.014057 *  
## XLeagueA     -62.59942   79.26140  -0.790 0.430424    
## XLeagueN            NA         NA      NA       NA    
## XDivisionW  -116.84925   40.36695  -2.895 0.004141 ** 
## XPutOuts       0.28189    0.07744   3.640 0.000333 ***
## XAssists       0.37107    0.22120   1.678 0.094723 .  
## XErrors       -3.36076    4.39163  -0.765 0.444857    
## XNewLeagueN  -24.76233   79.00263  -0.313 0.754218    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 315.6 on 243 degrees of freedom
## Multiple R-squared:  0.5461, Adjusted R-squared:  0.5106 
## F-statistic: 15.39 on 19 and 243 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{itemize}
\tightlist
\item
  ridge regression
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}} \DecValTok{70}
\NormalTok{ridge\_hitters }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(X, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ lambda)}
\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{coef}\NormalTok{(ridge\_hitters)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                        s0
## (Intercept)  5.647035e+01
## AtBat       -2.229055e-01
## Hits         1.646002e+00
## HmRun       -1.048269e+00
## Runs         1.179763e+00
## RBI          8.345634e-01
## Walks        2.432306e+00
## Years       -4.545099e+00
## CAtBat       8.238175e-03
## CHits        9.457440e-02
## CHmRun       5.890857e-01
## CRuns        1.881371e-01
## CRBI         1.937483e-01
## CWalks      -9.323679e-02
## LeagueA     -2.460078e+01
## LeagueN      2.460571e+01
## DivisionW   -1.142379e+02
## PutOuts      2.400898e-01
## Assists      9.822404e-02
## Errors      -3.021633e+00
## NewLeagueN  -1.031294e+01
\end{verbatim}

\begin{itemize}
\tightlist
\item
  coefficients
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_coefs }\OtherTok{\textless{}{-}} \FunctionTok{as.vector}\NormalTok{(}\FunctionTok{round}\NormalTok{(}\FunctionTok{coef}\NormalTok{(lm\_hitters), }\DecValTok{4}\NormalTok{))}
\NormalTok{ridge\_coefs }\OtherTok{\textless{}{-}} \FunctionTok{as.vector}\NormalTok{(}\FunctionTok{round}\NormalTok{(}\FunctionTok{coef}\NormalTok{(ridge\_hitters), }\DecValTok{4}\NormalTok{))}
\NormalTok{variables }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Intercept"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(X))}

\NormalTok{coefs }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{variable =}\NormalTok{ variables,}
  \AttributeTok{lm\_coefs =}\NormalTok{ lm\_coefs,}
  \AttributeTok{ridge\_coefs =}\NormalTok{ ridge\_coefs,}
  \AttributeTok{diff =}\NormalTok{ lm\_coefs }\SpecialCharTok{{-}}\NormalTok{ ridge\_coefs}
\NormalTok{)}

\NormalTok{coefs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      variable  lm_coefs ridge_coefs     diff
## 1   Intercept  225.7030     56.4703 169.2327
## 2       AtBat   -1.9799     -0.2229  -1.7570
## 3        Hits    7.5008      1.6460   5.8548
## 4       HmRun    4.3309     -1.0483   5.3792
## 5        Runs   -2.3762      1.1798  -3.5560
## 6         RBI   -1.0450      0.8346  -1.8796
## 7       Walks    6.2313      2.4323   3.7990
## 8       Years   -3.4891     -4.5451   1.0560
## 9      CAtBat   -0.1713      0.0082  -0.1795
## 10      CHits    0.1340      0.0946   0.0394
## 11     CHmRun   -0.1729      0.5891  -0.7620
## 12      CRuns    1.4543      0.1881   1.2662
## 13       CRBI    0.8077      0.1937   0.6140
## 14     CWalks   -0.8116     -0.0932  -0.7184
## 15    LeagueA  -62.5994    -24.6008 -37.9986
## 16    LeagueN        NA     24.6057       NA
## 17  DivisionW -116.8492   -114.2379  -2.6113
## 18    PutOuts    0.2819      0.2401   0.0418
## 19    Assists    0.3711      0.0982   0.2729
## 20     Errors   -3.3608     -3.0216  -0.3392
## 21 NewLeagueN  -24.7623    -10.3129 -14.4494
\end{verbatim}

I would say that ridge coefficients tend to be closer to zero and in
general smaller, than standard linear model ones.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  data split
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1122}\NormalTok{)}

\CommentTok{\# we\textquotesingle{}ll take 80\% train and 20\% test}
\NormalTok{train\_indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(hitters), }\AttributeTok{size =} \FloatTok{0.8} \SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(hitters))}
\NormalTok{hitters\_train }\OtherTok{\textless{}{-}}\NormalTok{ hitters[train\_indices, ]}
\NormalTok{hitters\_test }\OtherTok{\textless{}{-}}\NormalTok{ hitters[}\SpecialCharTok{{-}}\NormalTok{train\_indices, ]}

\CommentTok{\# design matrices}
\NormalTok{X\_train }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ hitters\_train)}
\NormalTok{y\_train }\OtherTok{\textless{}{-}}\NormalTok{ hitters\_train}\SpecialCharTok{$}\NormalTok{Salary}

\NormalTok{X\_test }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(Salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ hitters\_test)}
\NormalTok{y\_test }\OtherTok{\textless{}{-}}\NormalTok{ hitters\_test}\SpecialCharTok{$}\NormalTok{Salary}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  best lambda
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optimal\_lambda }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(lambda) \{}
\NormalTok{  ridge\_hitters\_train }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(X\_train, y\_train, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ lambda)}
\NormalTok{  pred\_hitters }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(ridge\_hitters\_train, }\AttributeTok{newx =}\NormalTok{ X\_test)}
\NormalTok{  mse }\OtherTok{\textless{}{-}} \FunctionTok{colMeans}\NormalTok{((pred\_hitters }\SpecialCharTok{{-}}\NormalTok{ y\_test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(mse)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{potential\_lambdas }\OtherTok{\textless{}{-}} \DecValTok{10}\SpecialCharTok{\^{}}\FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\AttributeTok{length =} \DecValTok{100}\NormalTok{)}
\NormalTok{mse\_ridge }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(potential\_lambdas, optimal\_lambda)}

\NormalTok{mse\_ridge\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{log\_lambda =} \FunctionTok{log}\NormalTok{(potential\_lambdas),}
  \AttributeTok{mse =}\NormalTok{ mse\_ridge}
\NormalTok{)}

\CommentTok{\# to display the needed point on the graph}
\NormalTok{best\_lambda\_ridge }\OtherTok{\textless{}{-}}\NormalTok{ potential\_lambdas[}\FunctionTok{which.min}\NormalTok{(mse\_ridge)]}
\NormalTok{min\_mse\_ridge }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(mse\_ridge)}

\FunctionTok{ggplot}\NormalTok{(mse\_ridge\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ log\_lambda, }\AttributeTok{y =}\NormalTok{ mse)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#818db2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{log}\NormalTok{(best\_lambda\_ridge), }\AttributeTok{y =}\NormalTok{ min\_mse\_ridge), }\AttributeTok{color =} \StringTok{"\#242824"}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"log(lambda)"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"MSE"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\AttributeTok{x =} \FunctionTok{log}\NormalTok{(best\_lambda\_ridge) }\SpecialCharTok{+} \DecValTok{7}\NormalTok{, }\AttributeTok{y =}\NormalTok{ min\_mse\_ridge,}
           \AttributeTok{label =} \FunctionTok{paste}\NormalTok{(}\StringTok{"min MSE = "}\NormalTok{, }\FunctionTok{round}\NormalTok{(min\_mse\_ridge, }\DecValTok{2}\NormalTok{),}
                         \StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{log(lambda) = "}\NormalTok{, }\FunctionTok{round}\NormalTok{(}\FunctionTok{log}\NormalTok{(best\_lambda\_ridge), }\DecValTok{2}\NormalTok{)),}
           \AttributeTok{vjust =} \SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"\#242824"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-64-1.pdf}}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  fitting with optimal lambda
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}}\NormalTok{ best\_lambda\_ridge}
\NormalTok{ridge\_hitters }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(X, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ lambda)}
\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{coef}\NormalTok{(ridge\_hitters)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                        s0
## (Intercept) 223.894005132
## AtBat         0.087821159
## Hits          0.359100399
## HmRun         1.158696741
## Runs          0.578919608
## RBI           0.578728301
## Walks         0.747276808
## Years         2.422873069
## CAtBat        0.007394323
## CHits         0.028411906
## CHmRun        0.211257547
## CRuns         0.056988201
## CRBI          0.058927048
## CWalks        0.057274196
## LeagueA      -2.658093515
## LeagueN       2.658241250
## DivisionW   -20.821649820
## PutOuts       0.050338927
## Assists       0.007143813
## Errors       -0.135505569
## NewLeagueN    2.484061051
\end{verbatim}

The most important variables are ones with bigger absolute values 1.
Division - players in the division W have much lower salaries than ones
in division e 2. League - being in league A is associated with lower
salaries, while league N players in general have higher 3. NewLeague -
players in the New League N tend to have higher salaries 4. Years - with
the increase in the num of years in the major leagues the salary also
increases

There are no coefficients that equal zero, as ridge regression doesn't
make coefficients equal to zero.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  lasso regression
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optimal\_lambda\_lasso }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(lambda) \{}
\NormalTok{  lasso\_hitters\_train }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(X\_train, y\_train, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ lambda)}
\NormalTok{  pred\_hitters }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lasso\_hitters\_train, }\AttributeTok{newx =}\NormalTok{ X\_test)}
\NormalTok{  mse }\OtherTok{\textless{}{-}} \FunctionTok{colMeans}\NormalTok{((pred\_hitters }\SpecialCharTok{{-}}\NormalTok{ y\_test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(mse)}
\NormalTok{\}}

\NormalTok{mse\_lasso }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(potential\_lambdas, optimal\_lambda\_lasso)}

\NormalTok{mse\_lasso\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{log\_lambda =} \FunctionTok{log}\NormalTok{(potential\_lambdas),}
  \AttributeTok{mse =}\NormalTok{ mse\_lasso}
\NormalTok{)}

\NormalTok{best\_lambda\_lasso }\OtherTok{\textless{}{-}}\NormalTok{ potential\_lambdas[}\FunctionTok{which.min}\NormalTok{(mse\_lasso)]}
\NormalTok{min\_mse\_lasso }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(mse\_lasso)}

\FunctionTok{ggplot}\NormalTok{(mse\_lasso\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ log\_lambda, }\AttributeTok{y =}\NormalTok{ mse)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#818db2"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{log}\NormalTok{(best\_lambda\_lasso), }\AttributeTok{y =}\NormalTok{ min\_mse\_lasso), }\AttributeTok{color =} \StringTok{"\#242824"}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"log(lambda)"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"MSE"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\AttributeTok{x =} \FunctionTok{log}\NormalTok{(best\_lambda\_lasso) }\SpecialCharTok{+} \DecValTok{7}\NormalTok{, }\AttributeTok{y =}\NormalTok{ min\_mse\_lasso,}
           \AttributeTok{label =} \FunctionTok{paste}\NormalTok{(}\StringTok{"min MSE = "}\NormalTok{, }\FunctionTok{round}\NormalTok{(min\_mse\_lasso, }\DecValTok{2}\NormalTok{),}
                         \StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{log(lambda) = "}\NormalTok{, }\FunctionTok{round}\NormalTok{(}\FunctionTok{log}\NormalTok{(best\_lambda\_lasso), }\DecValTok{2}\NormalTok{)),}
           \AttributeTok{vjust =} \SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"\#242824"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in geom_point(aes(x = log(best_lambda_lasso), y = min_mse_lasso), : All aesthetics have length 1, but the data has 100 rows.
## i Please consider using `annotate()` or provide this layer with data containing
##   a single row.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-66-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}}\NormalTok{ best\_lambda\_lasso}
\NormalTok{lasso\_hitters }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(X, y, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ lambda)}
\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{coef}\NormalTok{(lasso\_hitters)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                       s0
## (Intercept) 316.02183375
## AtBat         0.00000000
## Hits          0.72112214
## HmRun         0.00000000
## Runs          0.00000000
## RBI           0.00000000
## Walks         0.56907852
## Years         0.00000000
## CAtBat        0.00000000
## CHits         0.00000000
## CHmRun        0.00000000
## CRuns         0.09666601
## CRBI          0.25371287
## CWalks        0.00000000
## LeagueA       0.00000000
## LeagueN       0.00000000
## DivisionW     0.00000000
## PutOuts       0.00000000
## Assists       0.00000000
## Errors        0.00000000
## NewLeagueN    0.00000000
\end{verbatim}

The results are very different compared to the ridge regression. I
suppose, this happened because lasso regression sets some coefficients
to zero to ensure that no unsignificant variables are included in the
model. However, the important variables still differ between these two
models :( Maybe the most important conclusion we can get from this task
is that we should be careful while using the regularization and choose
the type correctly depending on the purpose of our research - prediction
or feature selection.

\subsubsection{Exercise 6}\label{exercise-6}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  GLM for donation with frequency and amount
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{donations }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}transfusion.data\textquotesingle{}}\NormalTok{)}
\FunctionTok{names}\NormalTok{(donations) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}recency\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}frequency\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}amount\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}time\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}donation\textquotesingle{}}\NormalTok{)}
\FunctionTok{head}\NormalTok{(donations)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   recency frequency amount time donation
## 1       2        50  12500   98        1
## 2       0        13   3250   28        1
## 3       1        16   4000   35        1
## 4       2        20   5000   45        1
## 5       1        24   6000   77        0
## 6       4         4   1000    4        0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(donations)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     recency         frequency          amount           time      
##  Min.   : 0.000   Min.   : 1.000   Min.   :  250   Min.   : 2.00  
##  1st Qu.: 2.750   1st Qu.: 2.000   1st Qu.:  500   1st Qu.:16.00  
##  Median : 7.000   Median : 4.000   Median : 1000   Median :28.00  
##  Mean   : 9.507   Mean   : 5.515   Mean   : 1379   Mean   :34.28  
##  3rd Qu.:14.000   3rd Qu.: 7.000   3rd Qu.: 1750   3rd Qu.:50.00  
##  Max.   :74.000   Max.   :50.000   Max.   :12500   Max.   :98.00  
##     donation    
##  Min.   :0.000  
##  1st Qu.:0.000  
##  Median :0.000  
##  Mean   :0.238  
##  3rd Qu.:0.000  
##  Max.   :1.000
\end{verbatim}

We will use the binomial family in the model, as we want to predict the
binary outcome

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# frequency GLM model}
\NormalTok{freq\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ frequency, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =}\NormalTok{ binomial)}
\FunctionTok{summary}\NormalTok{(freq\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ frequency, family = binomial, data = donations)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -1.63796    0.12822 -12.774  < 2e-16 ***
## frequency    0.07937    0.01514   5.243 1.58e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 789.12  on 746  degrees of freedom
## AIC: 793.12
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# amount GLM model}
\NormalTok{amount\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ amount, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =}\NormalTok{ binomial)}
\FunctionTok{summary}\NormalTok{(amount\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ amount, family = binomial, data = donations)
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -1.638e+00  1.282e-01 -12.774  < 2e-16 ***
## amount       3.175e-04  6.056e-05   5.243 1.58e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 789.12  on 746  degrees of freedom
## AIC: 793.12
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# comparing using AIC}
\FunctionTok{AIC}\NormalTok{(freq\_model, amount\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              df      AIC
## freq_model    2 793.1162
## amount_model  2 793.1162
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(donations, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ amount, }\AttributeTok{y =}\NormalTok{ frequency)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"amount"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"frequency"}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-68-1.pdf}}

Frequency and amount variables are highly correlated, which is logical
as the amount of blood taken is fixed and its sum depends only on the
frequency on donation We don't need both variables in our model, as
multicollinearity decreases its accuracy

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  different link functions
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{recency\_logit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(recency\_logit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency, family = binomial(link = "logit"), 
##     data = donations)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  -0.2032     0.1363  -1.492    0.136    
## recency      -0.1250     0.0165  -7.573 3.64e-14 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 743.55  on 746  degrees of freedom
## AIC: 747.55
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{recency\_probit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"probit"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(recency\_probit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency, family = binomial(link = "probit"), 
##     data = donations)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.159627   0.081631  -1.955   0.0505 .  
## recency     -0.069216   0.008766  -7.896 2.89e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 744.33  on 746  degrees of freedom
## AIC: 748.33
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{recency\_cauchit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"cauchit"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(recency\_probit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency, family = binomial(link = "probit"), 
##     data = donations)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.159627   0.081631  -1.955   0.0505 .  
## recency     -0.069216   0.008766  -7.896 2.89e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 744.33  on 746  degrees of freedom
## AIC: 748.33
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{recency\_log }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"log"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(recency\_probit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency, family = binomial(link = "probit"), 
##     data = donations)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.159627   0.081631  -1.955   0.0505 .  
## recency     -0.069216   0.008766  -7.896 2.89e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 744.33  on 746  degrees of freedom
## AIC: 748.33
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{recency\_cloglog }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency, }\AttributeTok{data =}\NormalTok{ donations, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"cloglog"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(recency\_cloglog)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency, family = binomial(link = "cloglog"), 
##     data = donations)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.47661    0.11101  -4.293 1.76e-05 ***
## recency     -0.11089    0.01482  -7.483 7.27e-14 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 820.89  on 747  degrees of freedom
## Residual deviance: 743.47  on 746  degrees of freedom
## AIC: 747.47
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{AIC}\NormalTok{(recency\_logit, recency\_probit, recency\_log, recency\_cauchit, recency\_cloglog)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 df      AIC
## recency_logit    2 747.5547
## recency_probit   2 748.3307
## recency_log      2 747.6188
## recency_cauchit  2 749.4959
## recency_cloglog  2 747.4671
\end{verbatim}

While comparing using AIC, the lowest result is obtained by
complementary log-log link, however, the results are not really
different from each other.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  best prediction
\end{enumerate}

\begin{itemize}
\tightlist
\item
  train and test data
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1122}\NormalTok{)}
\NormalTok{sample\_size }\OtherTok{\textless{}{-}} \DecValTok{374}
\NormalTok{train\_indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(donations), sample\_size)}
\NormalTok{donations\_train }\OtherTok{\textless{}{-}}\NormalTok{ donations[train\_indices, ]}
\NormalTok{donations\_test }\OtherTok{\textless{}{-}}\NormalTok{ donations[}\SpecialCharTok{{-}}\NormalTok{train\_indices, ]}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  model fit
\end{itemize}

We will not include amount there, as it is highly correlated with
frequency

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{donations\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency }\SpecialCharTok{+}\NormalTok{ frequency }\SpecialCharTok{+}\NormalTok{ time,}
  \AttributeTok{data =}\NormalTok{ donations\_train,}
  \AttributeTok{family =}\NormalTok{ binomial)}
\FunctionTok{summary}\NormalTok{(donations\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency + frequency + time, family = binomial, 
##     data = donations_train)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.351257   0.249155  -1.410 0.158600    
## recency     -0.094233   0.024035  -3.921 8.83e-05 ***
## frequency    0.131617   0.037421   3.517 0.000436 ***
## time        -0.025462   0.008412  -3.027 0.002471 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 415.04  on 373  degrees of freedom
## Residual deviance: 356.99  on 370  degrees of freedom
## AIC: 364.99
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_donations }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(donations\_model, }\AttributeTok{newx =}\NormalTok{ donations\_test)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  classification
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{treshhold }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{pred\_donations\_class }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(pred\_donations }\SpecialCharTok{\textless{}}\NormalTok{ treshhold, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{real\_donations\_class }\OtherTok{\textless{}{-}}\NormalTok{ donations\_test}\SpecialCharTok{$}\NormalTok{donation}
\NormalTok{CE }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(real\_donations\_class }\SpecialCharTok{{-}}\NormalTok{ pred\_donations\_class))}
\NormalTok{CE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2566845
\end{verbatim}

\begin{itemize}
\tightlist
\item
  model improvements
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  time and frequency may be correlated, as with increased time since
  first donation the frequency also may increase, if person is donated
  blood regularly. let's try to add interaction term between these two
  variables
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{donations\_model\_improved }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(donation }\SpecialCharTok{\textasciitilde{}}\NormalTok{ recency }\SpecialCharTok{+}\NormalTok{ frequency }\SpecialCharTok{*}\NormalTok{ time,}
  \AttributeTok{data =}\NormalTok{ donations\_train,}
  \AttributeTok{family =}\NormalTok{ binomial)}
\FunctionTok{summary}\NormalTok{(donations\_model\_improved)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = donation ~ recency + frequency * time, family = binomial, 
##     data = donations_train)
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(>|z|)    
## (Intercept)    -0.9337189  0.3126737  -2.986 0.002824 ** 
## recency        -0.0922556  0.0246590  -3.741 0.000183 ***
## frequency       0.3179350  0.0692661   4.590 4.43e-06 ***
## time           -0.0194856  0.0085715  -2.273 0.023008 *  
## frequency:time -0.0025151  0.0007484  -3.361 0.000778 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 415.04  on 373  degrees of freedom
## Residual deviance: 345.98  on 369  degrees of freedom
## AIC: 355.98
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_donations\_improved }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(donations\_model\_improved, }\AttributeTok{newx =}\NormalTok{ donations\_test)}
\NormalTok{pred\_donations\_improved\_\_class }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(pred\_donations\_improved }\SpecialCharTok{\textless{}}\NormalTok{ treshhold, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{CE }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(real\_donations\_class }\SpecialCharTok{{-}}\NormalTok{ pred\_donations\_improved\_\_class))}
\NormalTok{CE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2673797
\end{verbatim}

\subsubsection{Exercise 7}\label{exercise-7}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{student }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}student{-}mat.csv\textquotesingle{}}\NormalTok{)}
\FunctionTok{head}\NormalTok{(student)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   school sex age address famsize Pstatus Medu Fedu     Mjob     Fjob     reason
## 1     GP   F  18       U     GT3       A    4    4  at_home  teacher     course
## 2     GP   F  17       U     GT3       T    1    1  at_home    other     course
## 3     GP   F  15       U     LE3       T    1    1  at_home    other      other
## 4     GP   F  15       U     GT3       T    4    2   health services       home
## 5     GP   F  16       U     GT3       T    3    3    other    other       home
## 6     GP   M  16       U     LE3       T    4    3 services    other reputation
##   guardian traveltime studytime failures schoolsup famsup paid activities
## 1   mother          2         2        0       yes     no   no         no
## 2   father          1         2        0        no    yes   no         no
## 3   mother          1         2        3       yes     no  yes         no
## 4   mother          1         3        0        no    yes  yes        yes
## 5   father          1         2        0        no    yes  yes         no
## 6   mother          1         2        0        no    yes  yes        yes
##   nursery higher internet romantic famrel freetime goout Dalc Walc health
## 1     yes    yes       no       no      4        3     4    1    1      3
## 2      no    yes      yes       no      5        3     3    1    1      3
## 3     yes    yes      yes       no      4        3     2    2    3      3
## 4     yes    yes      yes      yes      3        2     2    1    1      5
## 5     yes    yes       no       no      4        3     2    1    2      5
## 6     yes    yes      yes       no      5        4     2    1    2      5
##   absences G1 G2 G3
## 1        6  5  6  6
## 2        4  5  5  6
## 3       10  7  8 10
## 4        2 15 14 15
## 5        4  6 10 10
## 6       10 15 15 15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(student)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     school              sex                 age         address         
##  Length:395         Length:395         Min.   :15.0   Length:395        
##  Class :character   Class :character   1st Qu.:16.0   Class :character  
##  Mode  :character   Mode  :character   Median :17.0   Mode  :character  
##                                        Mean   :16.7                     
##                                        3rd Qu.:18.0                     
##                                        Max.   :22.0                     
##    famsize            Pstatus               Medu            Fedu      
##  Length:395         Length:395         Min.   :0.000   Min.   :0.000  
##  Class :character   Class :character   1st Qu.:2.000   1st Qu.:2.000  
##  Mode  :character   Mode  :character   Median :3.000   Median :2.000  
##                                        Mean   :2.749   Mean   :2.522  
##                                        3rd Qu.:4.000   3rd Qu.:3.000  
##                                        Max.   :4.000   Max.   :4.000  
##      Mjob               Fjob              reason            guardian        
##  Length:395         Length:395         Length:395         Length:395        
##  Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                             
##                                                                             
##                                                                             
##    traveltime      studytime        failures       schoolsup        
##  Min.   :1.000   Min.   :1.000   Min.   :0.0000   Length:395        
##  1st Qu.:1.000   1st Qu.:1.000   1st Qu.:0.0000   Class :character  
##  Median :1.000   Median :2.000   Median :0.0000   Mode  :character  
##  Mean   :1.448   Mean   :2.035   Mean   :0.3342                     
##  3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:0.0000                     
##  Max.   :4.000   Max.   :4.000   Max.   :3.0000                     
##     famsup              paid            activities          nursery         
##  Length:395         Length:395         Length:395         Length:395        
##  Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                             
##                                                                             
##                                                                             
##     higher            internet           romantic             famrel     
##  Length:395         Length:395         Length:395         Min.   :1.000  
##  Class :character   Class :character   Class :character   1st Qu.:4.000  
##  Mode  :character   Mode  :character   Mode  :character   Median :4.000  
##                                                           Mean   :3.944  
##                                                           3rd Qu.:5.000  
##                                                           Max.   :5.000  
##     freetime         goout            Dalc            Walc      
##  Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:3.000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  
##  Median :3.000   Median :3.000   Median :1.000   Median :2.000  
##  Mean   :3.235   Mean   :3.109   Mean   :1.481   Mean   :2.291  
##  3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:3.000  
##  Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  
##      health         absences            G1              G2       
##  Min.   :1.000   Min.   : 0.000   Min.   : 3.00   Min.   : 0.00  
##  1st Qu.:3.000   1st Qu.: 0.000   1st Qu.: 8.00   1st Qu.: 9.00  
##  Median :4.000   Median : 4.000   Median :11.00   Median :11.00  
##  Mean   :3.554   Mean   : 5.709   Mean   :10.91   Mean   :10.71  
##  3rd Qu.:5.000   3rd Qu.: 8.000   3rd Qu.:13.00   3rd Qu.:13.00  
##  Max.   :5.000   Max.   :75.000   Max.   :19.00   Max.   :19.00  
##        G3       
##  Min.   : 0.00  
##  1st Qu.: 8.00  
##  Median :11.00  
##  Mean   :10.42  
##  3rd Qu.:14.00  
##  Max.   :20.00
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  G1, G2, G3 distributions
\end{enumerate}

\begin{itemize}
\tightlist
\item
  histograms
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{G1\_hist }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(student, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ G1)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}

\NormalTok{G2\_hist }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(student, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ G2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}

\NormalTok{G3\_hist }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(student, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ G3)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{bins =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}

\FunctionTok{ggarrange}\NormalTok{(G1\_hist, G2\_hist, G3\_hist, }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-75-1.pdf}}

The histograms do not seem to follow the normal distribution We can
check that using QQ-plots as well

\begin{itemize}
\tightlist
\item
  QQ plots
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{G1\_qq }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(student, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ G1)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}

\NormalTok{G2\_qq }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(student, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ G2)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}

\NormalTok{G3\_qq }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(student, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ G3)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}
    \AttributeTok{x =} \StringTok{"theoretical quantiles"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"empirical quantiles"}
\NormalTok{  )}

\FunctionTok{ggarrange}\NormalTok{(G1\_qq, G2\_qq, G3\_qq, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-76-1.pdf}}

G1, G2, G3 do not seem like they follow the normal distribution

\begin{itemize}
\tightlist
\item
  Poisson ?
\end{itemize}

To check whether they may follow the Poisson distribution we can check
if there is a significant difference between mean and variance:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(student}\SpecialCharTok{$}\NormalTok{G1) }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(student}\SpecialCharTok{$}\NormalTok{G1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.009918
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(student}\SpecialCharTok{$}\NormalTok{G2) }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(student}\SpecialCharTok{$}\NormalTok{G2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.32061
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(student}\SpecialCharTok{$}\NormalTok{G3) }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(student}\SpecialCharTok{$}\NormalTok{G3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.015289
\end{verbatim}

Looks like G1 and G2 may follow Poisson distribution (they're close to
be equal) while G3 probably is not However, we cannot state that there
is overdispersion in the distribution of these variables, as variance is
not highly bigger than the mean I also do not think that there are any
anomalies in their distributions, as looking at the histograms they seem
pretty close to Poisson

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  glm
\end{enumerate}

Fitting the model without G2 and G3 - these grades cannot influence the
first period grade, as they haven't happened yet

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_1 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(G1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{. }\SpecialCharTok{{-}}\NormalTok{G2 }\SpecialCharTok{{-}}\NormalTok{G3, }\AttributeTok{data =}\NormalTok{ student)}
\FunctionTok{summary}\NormalTok{(model\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = G1 ~ . - G2 - G3, data = student)
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)      11.375064   3.113004   3.654 0.000297 ***
## schoolMS          0.009965   0.549925   0.018 0.985553    
## sexM              0.894290   0.347385   2.574 0.010448 *  
## age              -0.070082   0.150905  -0.464 0.642639    
## addressU          0.150710   0.405805   0.371 0.710571    
## famsizeLE3        0.429175   0.339195   1.265 0.206602    
## PstatusT          0.154297   0.502913   0.307 0.759170    
## Medu              0.117943   0.224515   0.525 0.599688    
## Fedu              0.143774   0.192870   0.745 0.456496    
## Mjobhealth        0.926137   0.776837   1.192 0.233983    
## Mjobother        -0.782287   0.495455  -1.579 0.115244    
## Mjobservices      0.466532   0.554282   0.842 0.400529    
## Mjobteacher      -0.922790   0.721274  -1.279 0.201596    
## Fjobhealth       -0.553377   0.998994  -0.554 0.579973    
## Fjobother        -1.134849   0.710736  -1.597 0.111217    
## Fjobservices     -0.994008   0.734310  -1.354 0.176705    
## Fjobteacher       1.187017   0.900744   1.318 0.188414    
## reasonhome        0.165602   0.384744   0.430 0.667150    
## reasonother      -0.181207   0.567991  -0.319 0.749891    
## reasonreputation  0.444004   0.400557   1.108 0.268411    
## guardianmother    0.050219   0.379042   0.132 0.894673    
## guardianother     0.866380   0.694357   1.248 0.212947    
## traveltime       -0.025119   0.235489  -0.107 0.915112    
## studytime         0.604725   0.199842   3.026 0.002659 ** 
## failures         -1.314183   0.231280  -5.682 2.77e-08 ***
## schoolsupyes     -2.155394   0.463335  -4.652 4.65e-06 ***
## famsupyes        -0.978681   0.332560  -2.943 0.003466 ** 
## paidyes          -0.102389   0.331906  -0.308 0.757892    
## activitiesyes    -0.052728   0.309114  -0.171 0.864652    
## nurseryyes        0.029587   0.381623   0.078 0.938245    
## higheryes         1.140610   0.748777   1.523 0.128575    
## internetyes       0.255412   0.430423   0.593 0.553293    
## romanticyes      -0.211223   0.326001  -0.648 0.517455    
## famrel            0.025733   0.170852   0.151 0.880363    
## freetime          0.254817   0.164896   1.545 0.123161    
## goout            -0.413594   0.155971  -2.652 0.008367 ** 
## Dalc             -0.063146   0.229869  -0.275 0.783703    
## Walc             -0.025339   0.172300  -0.147 0.883164    
## health           -0.167531   0.111859  -1.498 0.135102    
## absences          0.012277   0.020124   0.610 0.542204    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 8.144982)
## 
##     Null deviance: 4340.7  on 394  degrees of freedom
## Residual deviance: 2891.5  on 355  degrees of freedom
## AIC: 1989.3
## 
## Number of Fisher Scoring iterations: 2
\end{verbatim}

At the significance level 0.05 the following variables are significant
for G1 - first period grade: * sexM - being a male increases the chances
of getting higher grade (that's sad) * studytime - with more time put
into studies, the grade gets higher * failures - the number of failures
has negative impact on the grade * schoolsup - having extra educational
support has strong negative influence * famsup - having extra family
support has negative influence side note: I guess here we see the
opposite causaition: usually children who are not very successful in the
education require additional support * goout - with increasing frequency
of going out the grade tends to decrease

The residual deviance is smaller than null deviance which suggests that
the model is better than the default one However, the deviance number is
still large which means we do not explain the data with our model
perfectly well, and it could be pred\_donations\_improved

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Pearson residuals}
\NormalTok{residuals\_pear }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(model\_1, }\AttributeTok{type =} \StringTok{"pearson"}\NormalTok{)}
\FunctionTok{hist}\NormalTok{(residuals\_pear)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-79-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqnorm}\NormalTok{(residuals\_pear)}
\FunctionTok{qqline}\NormalTok{(residuals\_pear)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-79-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Anscombe residuals}

\NormalTok{phi }\OtherTok{\textless{}{-}} \FunctionTok{deviance}\NormalTok{(model\_1) }\SpecialCharTok{/} \FunctionTok{df.residual}\NormalTok{(model\_1) }\CommentTok{\# estimated over{-}dispersion}

\NormalTok{residuals\_ansc }\OtherTok{\textless{}{-}} \FunctionTok{anscombe.residuals}\NormalTok{(model\_1, phi)}
\FunctionTok{hist}\NormalTok{(residuals\_ansc)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-80-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqnorm}\NormalTok{(residuals\_ansc)}
\FunctionTok{qqline}\NormalTok{(residuals\_ansc)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-80-2.pdf}}

These residuals do not seem to follow the normal distribution, so we
probably didn't capture all the influencing variables

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  less covariates
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_2 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(G1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ Fedu }\SpecialCharTok{+}\NormalTok{ studytime }\SpecialCharTok{+}\NormalTok{ failures }\SpecialCharTok{+}\NormalTok{ schoolsup }\SpecialCharTok{+}\NormalTok{ famsup }\SpecialCharTok{+}\NormalTok{ goout, }\AttributeTok{data =}\NormalTok{ student)}
\FunctionTok{summary}\NormalTok{(model\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = G1 ~ sex + Fedu + studytime + failures + schoolsup + 
##     famsup + goout, data = student)
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   10.4184     0.7355  14.165  < 2e-16 ***
## sexM           0.7544     0.3149   2.396 0.017068 *  
## Fedu           0.4613     0.1432   3.221 0.001387 ** 
## studytime      0.6476     0.1883   3.439 0.000649 ***
## failures      -1.2677     0.2099  -6.039 3.65e-09 ***
## schoolsupyes  -1.9928     0.4450  -4.478 9.93e-06 ***
## famsupyes     -0.7874     0.3142  -2.506 0.012618 *  
## goout         -0.3811     0.1341  -2.841 0.004739 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 8.547329)
## 
##     Null deviance: 4340.7  on 394  degrees of freedom
## Residual deviance: 3307.8  on 387  degrees of freedom
## AIC: 1978.4
## 
## Number of Fisher Scoring iterations: 2
\end{verbatim}

All the covariates are significant on alpha = 0.05

\begin{itemize}
\tightlist
\item
  sexM - being a male increases the chances of getting higher grade
\item
  Fedu - with higher level of education of father the grades also
  increase
\item
  studytime - with more time put into studies, the grade gets higher
\item
  failures - the number of failures has negative impact on the grade
\item
  schoolsup - having extra educational support has strong negative
  influence
\item
  famsup - having extra family support has negative influence side note
  here too: I guess here we see the opposite causaition: usually
  children who are not very successful in the education require
  additional support
\item
  goout - with increasing frequency of going out the grade tends to
  decrease
\end{itemize}

Again, the residual deviance is smaller than null, so model performs
better than null one, but not really much better

\begin{itemize}
\tightlist
\item
  deviance test: model\_1 and model\_2
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(model\_1, model\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: G1 ~ (school + sex + age + address + famsize + Pstatus + Medu + 
##     Fedu + Mjob + Fjob + reason + guardian + traveltime + studytime + 
##     failures + schoolsup + famsup + paid + activities + nursery + 
##     higher + internet + romantic + famrel + freetime + goout + 
##     Dalc + Walc + health + absences + G2 + G3) - G2 - G3
## Model 2: G1 ~ sex + Fedu + studytime + failures + schoolsup + famsup + 
##     goout
##   Resid. Df Resid. Dev  Df Deviance      F  Pr(>F)  
## 1       355     2891.5                              
## 2       387     3307.8 -32  -416.35 1.5974 0.02364 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The significant p-value (0.02364) suggests that Model 1 fits the data
better than Model 2. Which means that the variables we excluded still
explain a lot of variance and we should not omit them

\begin{itemize}
\tightlist
\item
  goout -\textgreater{} Walc
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_3 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(G1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ Fedu }\SpecialCharTok{+}\NormalTok{ studytime }\SpecialCharTok{+}\NormalTok{ failures }\SpecialCharTok{+}\NormalTok{ schoolsup }\SpecialCharTok{+}\NormalTok{ famsup }\SpecialCharTok{+}\NormalTok{ Walc, }\AttributeTok{data =}\NormalTok{ student)}
\FunctionTok{summary}\NormalTok{(model\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = G1 ~ sex + Fedu + studytime + failures + schoolsup + 
##     famsup + Walc, data = student)
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   10.0375     0.7016  14.306  < 2e-16 ***
## sexM           0.8575     0.3223   2.661  0.00813 ** 
## Fedu           0.4344     0.1433   3.031  0.00260 ** 
## studytime      0.5860     0.1916   3.059  0.00238 ** 
## failures      -1.2951     0.2100  -6.166 1.76e-09 ***
## schoolsupyes  -2.0073     0.4470  -4.490 9.40e-06 ***
## famsupyes     -0.7968     0.3154  -2.526  0.01193 *  
## Walc          -0.2805     0.1224  -2.292  0.02242 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 8.608663)
## 
##     Null deviance: 4340.7  on 394  degrees of freedom
## Residual deviance: 3331.6  on 387  degrees of freedom
## AIC: 1981.2
## 
## Number of Fisher Scoring iterations: 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(model\_2, model\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: G1 ~ sex + Fedu + studytime + failures + schoolsup + famsup + 
##     goout
## Model 2: G1 ~ sex + Fedu + studytime + failures + schoolsup + famsup + 
##     Walc
##   Resid. Df Resid. Dev Df Deviance F Pr(>F)
## 1       387     3307.8                     
## 2       387     3331.6  0  -23.736
\end{verbatim}

Weekend alcohol consumption is also a significant predictor, however, it
doesn't imrpove the fit compared to the model 2 - it even makes it worse
(higher residual deviance)

\subsubsection{Exercise 8}\label{exercise-8}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(landsat)}
\NormalTok{land }\OtherTok{\textless{}{-}}\NormalTok{ landsat}
\FunctionTok{head}\NormalTok{(land)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   SegmentsInCounty SegementID HACorn HASoybeans PixelsCorn PixelsSoybeans
## 1              545          1 165.76       8.09        374             55
## 2              566          1  96.32     106.03        209            218
## 3              394          1  76.08     103.60        253            250
## 4              424          1 185.35       6.47        432             96
## 5              424          2 116.43      63.82        367            178
## 6              564          1 162.08      43.50        361            137
##   MeanPixelsCorn MeanPixelsSoybeans outlier  CountyName
## 1         295.29             189.70   FALSE Cerro Gordo
## 2         300.40             196.65   FALSE    Hamilton
## 3         289.60             205.28   FALSE       Worth
## 4         290.74             220.22   FALSE    Humboldt
## 5         290.74             220.22   FALSE    Humboldt
## 6         318.21             188.06   FALSE    Franklin
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(land)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  SegmentsInCounty   SegementID        HACorn         HASoybeans    
##  Min.   :394.0    Min.   :1.000   Min.   : 64.75   Min.   :  6.47  
##  1st Qu.:556.0    1st Qu.:1.000   1st Qu.: 96.32   1st Qu.: 76.49  
##  Median :567.0    Median :2.000   Median :116.43   Median :102.59  
##  Mean   :605.8    Mean   :2.459   Mean   :120.32   Mean   : 95.35  
##  3rd Qu.:570.0    3rd Qu.:3.000   3rd Qu.:140.43   3rd Qu.:118.57  
##  Max.   :965.0    Max.   :6.000   Max.   :206.39   Max.   :174.34  
##                                                                    
##    PixelsCorn    PixelsSoybeans  MeanPixelsCorn  MeanPixelsSoybeans
##  Min.   :145.0   Min.   : 55.0   Min.   :257.2   Min.   :177.1     
##  1st Qu.:246.0   1st Qu.:167.0   1st Qu.:290.7   1st Qu.:188.1     
##  Median :295.0   Median :206.0   Median :298.6   Median :198.7     
##  Mean   :297.4   Mean   :203.3   Mean   :298.4   Mean   :206.1     
##  3rd Qu.:353.0   3rd Qu.:249.0   3rd Qu.:314.3   3rd Qu.:221.4     
##  Max.   :459.0   Max.   :345.0   Max.   :326.0   Max.   :247.1     
##                                                                    
##   outlier             CountyName
##  Mode :logical   Hardin    : 6  
##  FALSE:36        Hancock   : 5  
##  TRUE :1         Kossuth   : 5  
##                  Webster   : 4  
##                  Franklin  : 3  
##                  Pocahontas: 3  
##                  (Other)   :11
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  linear model
\end{enumerate}

\begin{itemize}
\tightlist
\item
  corn
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{corn\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(HACorn }\SpecialCharTok{\textasciitilde{}}\NormalTok{ PixelsCorn }\SpecialCharTok{+}\NormalTok{ MeanPixelsCorn }\SpecialCharTok{+}\NormalTok{ SegmentsInCounty, }\AttributeTok{random =} \SpecialCharTok{\textasciitilde{}}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ CountyName, }\AttributeTok{data =}\NormalTok{ land)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
##  extra argument 'random' will be disregarded
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(corn\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = HACorn ~ PixelsCorn + MeanPixelsCorn + SegmentsInCounty, 
##     data = land, random = ~1 | CountyName)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -46.187  -9.592   1.349  13.429  36.783 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(>|t|)    
## (Intercept)      51.42743   45.07137   1.141    0.262    
## PixelsCorn        0.38938    0.04558   8.543 7.15e-10 ***
## MeanPixelsCorn   -0.11495    0.14514  -0.792    0.434    
## SegmentsInCounty -0.02080    0.01933  -1.076    0.290    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 18.74 on 33 degrees of freedom
## Multiple R-squared:  0.696,  Adjusted R-squared:  0.6683 
## F-statistic: 25.18 on 3 and 33 DF,  p-value: 1.162e-08
\end{verbatim}

\subsubsection{Exercise 9}\label{exercise-9}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(iris)}
\NormalTok{iris }\OtherTok{\textless{}{-}}\NormalTok{ iris}
\FunctionTok{head}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa
## 6          5.4         3.9          1.7         0.4  setosa
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
##  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
##        Species  
##  setosa    :50  
##  versicolor:50  
##  virginica :50  
##                 
##                 
## 
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  reduced dataset
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_cut }\OtherTok{\textless{}{-}}\NormalTok{ iris }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(., }\SpecialCharTok{{-}}\NormalTok{Species) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{pca }\OtherTok{\textless{}{-}} \FunctionTok{prcomp}\NormalTok{(iris\_cut, }\AttributeTok{scale. =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(pca)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Importance of components:
##                           PC1     PC2    PC3     PC4
## Standard deviation     2.0563 0.49262 0.2797 0.15439
## Proportion of Variance 0.9246 0.05307 0.0171 0.00521
## Cumulative Proportion  0.9246 0.97769 0.9948 1.00000
\end{verbatim}

According to the summary, PC1 and PC2 explain 92.46\% + 5.307\% =
97.767\% proportion of the variance

\begin{itemize}
\tightlist
\item
  loadings
\end{itemize}

Loadings are the eigenvectors of the covariance matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cov\_iris }\OtherTok{\textless{}{-}} \FunctionTok{cov}\NormalTok{(iris\_cut) }\CommentTok{\# covariance matrix}
\NormalTok{eigen\_decomposition }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(cov\_iris)}
\NormalTok{loadings }\OtherTok{\textless{}{-}}\NormalTok{ eigen\_decomposition}\SpecialCharTok{$}\NormalTok{vectors}
\NormalTok{loadings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]        [,2]        [,3]       [,4]
## [1,]  0.36138659 -0.65658877  0.58202985  0.3154872
## [2,] -0.08452251 -0.73016143 -0.59791083 -0.3197231
## [3,]  0.85667061  0.17337266 -0.07623608 -0.4798390
## [4,]  0.35828920  0.07548102 -0.54583143  0.7536574
\end{verbatim}

\begin{itemize}
\tightlist
\item
  scores
\end{itemize}

Scores are projections onto loadings

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scores }\OtherTok{\textless{}{-}}\NormalTok{ iris\_cut }\SpecialCharTok{\%*\%}\NormalTok{ loadings}
\NormalTok{scores}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]      [,2]        [,3]         [,4]
##   [1,] 2.818240 -5.646350  0.65976754 -0.031089276
##   [2,] 2.788223 -5.149951  0.84231699  0.065674837
##   [3,] 2.613375 -5.182003  0.61395246 -0.013383323
##   [4,] 2.757022 -5.008654  0.60029334 -0.108927529
##   [5,] 2.773649 -5.653707  0.54177348 -0.094610305
##   [6,] 3.221505 -6.068283  0.46317506 -0.057552570
##   [7,] 2.681827 -5.237491  0.37396056 -0.081494819
##   [8,] 2.876220 -5.490338  0.65373203 -0.078649583
##   [9,] 2.615982 -4.748641  0.61109315 -0.060096449
##  [10,] 2.829609 -5.213178  0.82948544 -0.089647114
##  [11,] 2.995418 -5.972021  0.70717073 -0.048371637
##  [12,] 2.889610 -5.341683  0.52970246 -0.189730921
##  [13,] 2.716256 -5.091841  0.83869715 -0.041239624
##  [14,] 2.278561 -4.815558  0.57055304 -0.055031525
##  [15,] 2.857615 -6.505717  0.78348024  0.125858005
##  [16,] 3.116326 -6.665015  0.35407581 -0.026800167
##  [17,] 2.878837 -6.137632  0.49366949  0.134383024
##  [18,] 2.854068 -5.638802  0.60518440  0.044276467
##  [19,] 3.302545 -6.199792  0.75215824 -0.006299845
##  [20,] 2.914379 -5.840513  0.41818754 -0.099624363
##  [21,] 3.192109 -5.718299  0.87129676 -0.048422504
##  [22,] 2.958660 -5.759949  0.42339548  0.007713690
##  [23,] 2.286426 -5.460421  0.33945597 -0.028869588
##  [24,] 3.199632 -5.425661  0.59272946  0.115000876
##  [25,] 3.146611 -5.289671  0.50683163 -0.333682617
##  [26,] 2.995696 -5.180936  0.88527276  0.001255759
##  [27,] 3.033545 -5.457904  0.53694214  0.024098003
##  [28,] 2.940045 -5.694671  0.71034692 -0.047524455
##  [29,] 2.862830 -5.638993  0.77776161  0.032431754
##  [30,] 2.870376 -5.129991  0.59108164 -0.157335019
##  [31,] 2.914967 -5.122634  0.70907571 -0.093813990
##  [32,] 3.092433 -5.737877  0.77737769  0.198276779
##  [33,] 2.853503 -6.140316  0.40618357 -0.314724060
##  [34,] 2.903628 -6.420098  0.47404190 -0.128700571
##  [35,] 2.865438 -5.205630  0.77490230 -0.014281372
##  [36,] 2.636123 -5.396317  0.79618502  0.129246733
##  [37,] 2.877127 -5.926323  0.90020309  0.143089500
##  [38,] 2.701681 -5.595596  0.53815363 -0.201524767
##  [39,] 2.521863 -4.838994  0.55892567 -0.044084860
##  [40,] 2.912359 -5.555996  0.71193502 -0.047100864
##  [41,] 2.732263 -5.590480  0.55460502  0.060711646
##  [42,] 2.652996 -4.385992  0.98108309  0.286635774
##  [43,] 2.504959 -4.985027  0.43934350 -0.108029481
##  [44,] 3.096751 -5.515824  0.36798477  0.142857178
##  [45,] 3.292876 -5.763616  0.33310997 -0.216194215
##  [46,] 2.787914 -5.076744  0.72953086  0.109491861
##  [47,] 2.964217 -5.830724  0.46514708 -0.222974004
##  [48,] 2.662903 -5.099007  0.54812587 -0.092915941
##  [49,] 2.959279 -5.906363  0.64896774 -0.079920357
##  [50,] 2.799005 -5.434659  0.72114672  0.001306626
##  [51,] 6.787191 -6.012113  1.03842074 -0.014826425
##  [52,] 6.434854 -5.645286  0.64986690 -0.032785201
##  [53,] 6.966667 -5.831215  0.97017848 -0.035004889
##  [54,] 5.685683 -4.498994  0.81144411  0.060215127
##  [55,] 6.590468 -5.401543  0.93961061  0.078668861
##  [56,] 6.144034 -4.908706  0.59077663 -0.276468479
##  [57,] 6.597426 -5.610421  0.46204248 -0.116908285
##  [58,] 4.753242 -4.322062  0.61954980 -0.051259435
##  [59,] 6.546497 -5.555314  1.04718880 -0.072486215
##  [60,] 5.493620 -4.603871  0.35071128 -0.038970631
##  [61,] 4.994524 -4.060981  0.90166990  0.012210728
##  [62,] 6.014064 -5.222971  0.50130497  0.017367520
##  [63,] 5.767342 -4.776916  1.32599955  0.023833807
##  [64,] 6.487300 -5.202135  0.69396712 -0.202847967
##  [65,] 5.328440 -5.072098  0.54139503  0.091865579
##  [66,] 6.430226 -5.794132  0.94647369  0.066451424
##  [67,] 6.162649 -4.973983  0.30382519 -0.221230334
##  [68,] 5.738470 -4.993342  0.90301455 -0.247109082
##  [69,] 6.447099 -4.783807  1.13137176  0.223840464
##  [70,] 5.547592 -4.743118  0.86685482 -0.074928360
##  [71,] 6.618648 -5.242336  0.17223172 -0.108383266
##  [72,] 5.860254 -5.258028  0.86170660  0.089645891
##  [73,] 6.800549 -4.999165  0.97970707 -0.032463342
##  [74,] 6.424094 -5.144215  0.86292449 -0.321607142
##  [75,] 6.217218 -5.476009  0.95365365  0.008368043
##  [76,] 6.402540 -5.655457  0.94806179  0.066875015
##  [77,] 6.834390 -5.571393  1.15355550  0.001981479
##  [78,] 7.060167 -5.594448  0.79677370  0.036617569
##  [79,] 6.315656 -5.163602  0.59642821 -0.063063147
##  [80,] 5.196781 -4.958690  0.95034430  0.041217901
##  [81,] 5.434239 -4.621780  0.87606653 -0.026520871
##  [82,] 5.312743 -4.646666  0.93827328 -0.053902714
##  [83,] 5.638794 -5.012920  0.80909548 -0.000409800
##  [84,] 6.882392 -4.905998  0.61568559 -0.211656176
##  [85,] 6.090372 -4.842665  0.18741922 -0.284327773
##  [86,] 6.309223 -5.521135  0.24288965 -0.147558956
##  [87,] 6.723056 -5.734572  0.86901973 -0.002134530
##  [88,] 6.317460 -4.954916  1.24657356  0.120669287
##  [89,] 5.748323 -5.058428  0.44348590 -0.180026225
##  [90,] 5.668778 -4.645026  0.69186194 -0.003729493
##  [91,] 5.967165 -4.656241  0.65615957 -0.303003141
##  [92,] 6.393180 -5.292488  0.64179965 -0.186836379
##  [93,] 5.732913 -4.922567  0.86126296 -0.016421388
##  [94,] 4.797833 -4.314704  0.73754387  0.012261594
##  [95,] 5.859347 -4.822042  0.61523555 -0.132093192
##  [96,] 5.834300 -5.114298  0.54864843 -0.271827147
##  [97,] 5.878581 -5.033734  0.55385637 -0.164489094
##  [98,] 6.144941 -5.344691  0.83724768 -0.054729396
##  [99,] 4.595895 -4.570859  0.64445236  0.199183131
## [100,] 5.801366 -4.978055  0.62127106 -0.084532885
## [101,] 8.033558 -5.317103 -0.12831271 -0.062407286
## [102,] 6.917601 -4.752036  0.33553019 -0.048656387
## [103,] 8.119041 -5.670856  0.74264060  0.032420328
## [104,] 7.473896 -5.147225  0.52342805 -0.270142647
## [105,] 7.852371 -5.286692  0.34646315 -0.033522346
## [106,] 8.899404 -5.877789  0.98029027 -0.145723366
## [107,] 6.023597 -4.134194  0.08619342 -0.131478332
## [108,] 8.434952 -5.682453  1.05209265 -0.290542745
## [109,] 7.823594 -5.083121  0.98015711 -0.112026326
## [110,] 8.419116 -6.109745  0.20851730  0.077630358
## [111,] 7.164139 -5.569181  0.38941253  0.087688839
## [112,] 7.305767 -5.111315  0.66950088  0.044668132
## [113,] 7.667957 -5.543228  0.59852607  0.129709765
## [114,] 6.848529 -4.550134  0.34994983  0.107089156
## [115,] 7.088293 -4.787312  0.00282339  0.296200016
## [116,] 7.406822 -5.446203  0.15221290  0.186269550
## [117,] 7.452054 -5.368896  0.58766655 -0.191033620
## [118,] 8.989420 -6.502692  0.49795784 -0.342571286
## [119,] 9.298011 -5.584276  1.14562048  0.020494384
## [120,] 6.803157 -4.565803  0.97684775 -0.079176468
## [121,] 7.930183 -5.705149  0.41273339  0.152077552
## [122,] 6.701366 -4.720861  0.11999721  0.027607404
## [123,] 9.002285 -5.787627  1.20503496 -0.173579667
## [124,] 6.891131 -5.122553  0.69637547  0.129689265
## [125,] 7.777796 -5.661943  0.34570262 -0.093723682
## [126,] 8.116456 -5.887854  0.83738724 -0.274056699
## [127,] 6.760873 -5.147248  0.58600501  0.114152134
## [128,] 6.793497 -5.210284  0.40059625 -0.029325105
## [129,] 7.625974 -5.117223  0.47767269  0.019475610
## [130,] 7.890368 -5.791592  1.08138291 -0.264875766
## [131,] 8.344038 -5.702222  1.13075079 -0.055688175
## [132,] 8.733039 -6.701118  0.74640092 -0.286253636
## [133,] 7.661803 -5.109675  0.42308955  0.094841353
## [134,] 6.946526 -5.183539  0.78508660 -0.224348071
## [135,] 7.283660 -4.827051  0.80472791 -0.538786125
## [136,] 8.578865 -6.015038  0.96744501  0.276476332
## [137,] 7.646608 -5.467017 -0.10302622  0.022190256
## [138,] 7.407463 -5.376253  0.46967248 -0.254554650
## [139,] 6.671691 -5.161962  0.35001688 -0.012889926
## [140,] 7.609976 -5.699240  0.60456158  0.177270073
## [141,] 7.816520 -5.510604  0.30915897  0.244302065
## [142,] 7.424633 -5.736156  0.51826612  0.471953254
## [143,] 6.917601 -4.752036  0.33553019 -0.048656387
## [144,] 8.065379 -5.604815  0.33928319  0.024561035
## [145,] 7.921111 -5.631751  0.12737005  0.207739288
## [146,] 7.446475 -5.514485  0.45402763  0.392844227
## [147,] 7.029532 -4.951636  0.75375089  0.221015729
## [148,] 7.266711 -5.405811  0.50137108  0.103649561
## [149,] 7.403307 -5.443581 -0.09139885  0.011243592
## [150,] 6.892554 -5.044292  0.26894307 -0.188390341
\end{verbatim}

Order of the columns: * Sepal.Length * Sepal.Width * Petal.Length *
Petal.Width

Looking at the loadings, PC1 is mostly influenced by Petal Length and a
bit less of Petal Width, while PC2 is negatively associated by Sepal
Length and Width

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  correlation matrix
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_iris }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(iris\_cut) }\CommentTok{\# correlation matrix}
\NormalTok{eigen\_decomposition\_cor }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(cor\_iris)}
\NormalTok{loadings\_cor }\OtherTok{\textless{}{-}}\NormalTok{ eigen\_decomposition\_cor}\SpecialCharTok{$}\NormalTok{vectors}
\NormalTok{loadings\_cor}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]        [,2]       [,3]       [,4]
## [1,]  0.5210659 -0.37741762  0.7195664  0.2612863
## [2,] -0.2693474 -0.92329566 -0.2443818 -0.1235096
## [3,]  0.5804131 -0.02449161 -0.1421264 -0.8014492
## [4,]  0.5648565 -0.06694199 -0.6342727  0.5235971
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scores\_cor }\OtherTok{\textless{}{-}}\NormalTok{ iris\_cut }\SpecialCharTok{\%*\%}\NormalTok{ loadings\_cor}
\NormalTok{scores\_cor}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]      [,2]     [,3]         [,4]
##   [1,] 2.640270 -5.204041 2.488621 -0.117033159
##   [2,] 2.670730 -4.666910 2.466898 -0.107535605
##   [3,] 2.454606 -4.773636 2.288321 -0.104349860
##   [4,] 2.545517 -4.648463 2.212378 -0.278417376
##   [5,] 2.561228 -5.258629 2.392226 -0.155512749
##   [6,] 2.975946 -5.707321 2.437245 -0.223766470
##   [7,] 2.463157 -4.929697 2.089848 -0.182965623
##   [8,] 2.673139 -5.076419 2.426890 -0.210955749
##   [9,] 2.437132 -4.385872 2.131553 -0.225827783
##  [10,] 2.645351 -4.754994 2.491675 -0.252391205
##  [11,] 2.800761 -5.504375 2.641402 -0.143494123
##  [12,] 2.626967 -5.003385 2.268764 -0.343357930
##  [13,] 2.562138 -4.622474 2.458369 -0.186023946
##  [14,] 2.127481 -4.426418 2.141224 -0.076232312
##  [15,] 2.754260 -5.924983 2.898552  0.164402277
##  [16,] 2.881509 -6.277296 2.559350 -0.046845546
##  [17,] 2.743781 -5.697524 2.494096  0.096813229
##  [18,] 2.696755 -5.210735 2.425193 -0.064673445
##  [19,] 3.102715 -5.721522 2.740981 -0.185389337
##  [20,] 2.673992 -5.490173 2.337666 -0.181871256
##  [21,] 2.997648 -5.232284 2.686291 -0.266731087
##  [22,] 2.757413 -5.404538 2.298677 -0.117160580
##  [23,] 2.120637 -5.097865 2.161250  0.060552438
##  [24,] 3.037720 -5.046812 2.304577 -0.175686868
##  [25,] 2.801091 -5.010732 2.226126 -0.583792704
##  [26,] 2.838920 -4.709550 2.510430 -0.241696826
##  [27,] 2.844152 -5.092257 2.285822 -0.186381247
##  [28,] 2.750418 -5.244232 2.546365 -0.171049455
##  [29,] 2.719311 -5.149453 2.585016 -0.078553569
##  [30,] 2.628730 -4.780984 2.245683 -0.344784634
##  [31,] 2.707772 -4.726396 2.342078 -0.306305044
##  [32,] 2.994537 -5.240775 2.587862 -0.001721811
##  [33,] 2.532324 -5.791515 2.463163 -0.297514941
##  [34,] 2.660153 -6.001315 2.605380 -0.098975380
##  [35,] 2.701837 -4.761689 2.428248 -0.200031492
##  [36,] 2.552885 -4.884413 2.518404  0.054180948
##  [37,] 2.790655 -5.352559 2.790660  0.067626278
##  [38,] 2.452636 -5.214193 2.383697 -0.234001090
##  [39,] 2.352156 -4.475752 2.121328 -0.158033820
##  [40,] 2.725246 -5.114161 2.498846 -0.184827121
##  [41,] 2.586608 -5.170545 2.367449 -0.010657149
##  [42,] 2.649291 -3.873881 2.300924  0.006911255
##  [43,] 2.298287 -4.660411 2.072451 -0.182735744
##  [44,] 2.930188 -5.197975 2.134530 -0.094012782
##  [45,] 2.962643 -5.506664 2.217388 -0.450091241
##  [46,] 2.675109 -4.635862 2.331514 -0.081304519
##  [47,] 2.675548 -5.485928 2.386881 -0.314375894
##  [48,] 2.460541 -4.738344 2.202152 -0.210623413
##  [49,] 2.748655 -5.466633 2.569445 -0.169622751
##  [50,] 2.642033 -4.981640 2.465540 -0.118459863
##  [51,] 6.304290 -5.805299 2.698967 -1.600002292
##  [52,] 5.932054 -5.580644 2.232225 -1.544124498
##  [53,] 6.451687 -5.686820 2.559596 -1.721710094
##  [54,] 5.302329 -4.384368 2.002477 -1.372118296
##  [55,] 6.149941 -5.251517 2.387722 -1.548736946
##  [56,] 5.562075 -4.933745 1.953136 -1.782340473
##  [57,] 6.025581 -5.646824 2.043978 -1.690534223
##  [58,] 4.387009 -4.213020 1.836069 -1.137305694
##  [59,] 6.062141 -5.368200 2.562095 -1.639678707
##  [60,] 5.036715 -4.644706 1.639640 -1.367403389
##  [61,] 4.662937 -3.886342 1.977353 -1.222063067
##  [62,] 5.551266 -5.199929 1.963956 -1.409630940
##  [63,] 5.420340 -4.460665 2.576980 -1.386203334
##  [64,] 5.916135 -5.188634 2.124672 -1.798107058
##  [65,] 4.960662 -4.966290 1.984655 -1.099515741
##  [66,] 6.000781 -5.592396 2.550173 -1.425602441
##  [67,] 5.569071 -5.094051 1.705448 -1.728451598
##  [68,] 5.239494 -4.849278 2.296663 -1.580360325
##  [69,] 6.097188 -4.581865 2.332694 -1.472872134
##  [70,] 5.129554 -4.590931 2.166624 -1.395266094
##  [71,] 6.015102 -5.419365 1.639522 -1.758123271
##  [72,] 5.480295 -5.072466 2.312026 -1.277101338
##  [73,] 6.300656 -4.906392 2.274485 -1.804376090
##  [74,] 5.830099 -5.082916 2.275965 -1.890475523
##  [75,] 5.783804 -5.285369 2.460820 -1.451501189
##  [76,] 5.975609 -5.462325 2.502655 -1.439380107
##  [77,] 6.365857 -5.362946 2.638594 -1.683000625
##  [78,] 6.545421 -5.534844 2.299054 -1.737041886
##  [79,] 5.804432 -5.152688 2.017713 -1.611586124
##  [80,] 4.866075 -4.704512 2.334421 -1.113268443
##  [81,] 5.046341 -4.458411 2.133318 -1.328898835
##  [82,] 4.931814 -4.449267 2.210958 -1.301113624
##  [83,] 5.236383 -4.857768 2.198234 -1.315351048
##  [84,] 6.263035 -4.989418 1.917886 -2.015394034
##  [85,] 5.464857 -5.018567 1.561535 -1.780708854
##  [86,] 5.726244 -5.621030 1.832095 -1.620981220
##  [87,] 6.231391 -5.606438 2.444108 -1.613677501
##  [88,] 5.951347 -4.696099 2.521279 -1.483668970
##  [89,] 5.223934 -5.070866 1.889154 -1.512591326
##  [90,] 5.248460 -4.569027 1.953600 -1.396820220
##  [91,] 5.397205 -4.664459 1.935739 -1.782110594
##  [92,] 5.831159 -5.278515 2.114446 -1.730313096
##  [93,] 5.321359 -4.767888 2.208459 -1.383145011
##  [94,] 4.466050 -4.158432 1.932464 -1.098826104
##  [95,] 5.362780 -4.796326 1.948255 -1.555683365
##  [96,] 5.277596 -5.104363 2.010325 -1.618967336
##  [97,] 5.361017 -5.018727 1.971336 -1.554256661
##  [98,] 5.679591 -5.209885 2.316906 -1.503758445
##  [99,] 4.346649 -4.380180 1.934755 -0.804604912
## [100,] 5.329910 -4.923948 2.009987 -1.461760774
## [101,] 7.288489 -5.738911 1.288368 -2.261180823
## [102,] 6.328278 -4.934017 1.583691 -1.910572150
## [103,] 7.502162 -5.734631 2.205257 -2.144392842
## [104,] 6.768663 -5.312937 1.886962 -2.257715270
## [105,] 7.187966 -5.512425 1.724303 -2.168659972
## [106,] 8.168984 -5.940484 2.465552 -2.574764174
## [107,] 5.451969 -4.381599 1.197088 -1.744877757
## [108,] 7.696018 -5.707499 2.507040 -2.557443463
## [109,] 7.200911 -5.099484 2.244116 -2.264086760
## [110,] 7.734685 -6.358025 1.848451 -2.143220981
## [111,] 6.614836 -5.666552 1.901770 -1.737066850
## [112,] 6.757001 -5.165366 1.987006 -1.914090231
## [113,] 7.113677 -5.611609 2.046238 -1.902199027
## [114,] 6.328486 -4.715862 1.511396 -1.779494216
## [115,] 6.583772 -5.059818 1.242117 -1.661124544
## [116,] 6.848269 -5.653791 1.611106 -1.766406187
## [117,] 6.787900 -5.478301 2.020650 -2.137664052
## [118,] 8.120139 -6.726005 2.264363 -2.675228453
## [119,] 8.615925 -5.629643 2.465769 -2.634947046
## [120,] 6.283181 -4.518627 2.117717 -1.925854013
## [121,] 7.340968 -5.852296 1.914039 -1.956342746
## [122,] 6.137534 -4.952659 1.380338 -1.762530805
## [123,] 8.276516 -5.789321 2.635600 -2.656438261
## [124,] 6.416243 -5.111134 2.035327 -1.671998874
## [125,] 7.096848 -5.855754 1.872542 -2.125670390
## [126,] 7.388983 -5.939398 2.404407 -2.380190203
## [127,] 6.279160 -5.163272 1.953145 -1.630333539
## [128,] 6.231226 -5.312639 1.818099 -1.761309016
## [129,] 7.017161 -5.278432 1.793075 -2.062156540
## [130,] 7.213799 -5.736452 2.608563 -2.299917857
## [131,] 7.715462 -5.654707 2.568433 -2.306314310
## [132,] 7.937257 -6.780753 2.577769 -2.487255850
## [133,] 7.073647 -5.285126 1.729648 -2.009796827
## [134,] 6.335934 -5.188279 2.172745 -2.001718826
## [135,] 6.519311 -4.933688 2.070073 -2.482358494
## [136,] 8.043855 -5.979368 2.481717 -2.043191496
## [137,] 6.972903 -5.814750 1.384208 -2.005311799
## [138,] 6.708859 -5.532889 1.924255 -2.176143642
## [139,] 6.121078 -5.272448 1.760355 -1.707292719
## [140,] 7.080807 -5.739231 2.107969 -1.808276437
## [141,] 7.262134 -5.688728 1.745349 -1.863744402
## [142,] 7.019655 -5.745272 2.023753 -1.463122236
## [143,] 6.328278 -4.934017 1.583691 -1.910572150
## [144,] 7.404944 -5.819453 1.813657 -2.142761223
## [145,] 7.322791 -5.882531 1.618833 -1.916231537
## [146,] 7.000417 -5.579908 1.890065 -1.583173455
## [147,] 6.584640 -4.935618 2.006564 -1.675082161
## [148,] 6.726747 -5.484342 1.936433 -1.792509851
## [149,] 6.748228 -5.765416 1.404104 -1.923510292
## [150,] 6.243095 -5.242054 1.645761 -1.973856121
\end{verbatim}

While using correlation matrix for PCA, components have equal weight and
emportance, therefore, loadings for all principal components are more
equally distributed than ones calculated using covariance matrix.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  millimeters
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_cut\_mil }\OtherTok{\textless{}{-}}\NormalTok{ iris\_cut}
\NormalTok{iris\_cut\_mil[, }\StringTok{"Petal.Length"}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ iris\_cut[, }\StringTok{"Petal.Length"}\NormalTok{] }\SpecialCharTok{*} \DecValTok{10}
\FunctionTok{head}\NormalTok{(iris\_cut\_mil)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Sepal.Length Sepal.Width Petal.Length Petal.Width
## [1,]          5.1         3.5           14         0.2
## [2,]          4.9         3.0           14         0.2
## [3,]          4.7         3.2           13         0.2
## [4,]          4.6         3.1           15         0.2
## [5,]          5.0         3.6           14         0.2
## [6,]          5.4         3.9           17         0.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca\_mil }\OtherTok{\textless{}{-}} \FunctionTok{prcomp}\NormalTok{(iris\_cut\_mil, }\AttributeTok{scale. =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(pca\_mil)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Importance of components:
##                            PC1     PC2     PC3    PC4
## Standard deviation     17.6840 0.50221 0.28081 0.1754
## Proportion of Variance  0.9988 0.00081 0.00025 0.0001
## Cumulative Proportion   0.9988 0.99965 0.99990 1.0000
\end{verbatim}

The proportion of variance has highly changed to having more weight on
the first PC (99.88\%) and leaving just small proportion of variance for
the last three components

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cov\_iris\_mil }\OtherTok{\textless{}{-}} \FunctionTok{cov}\NormalTok{(iris\_cut\_mil) }\CommentTok{\# covariance matrix}
\NormalTok{eigen\_decomposition\_mil }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(cov\_iris\_mil)}
\NormalTok{loadings\_mil }\OtherTok{\textless{}{-}}\NormalTok{ eigen\_decomposition\_mil}\SpecialCharTok{$}\NormalTok{vectors}
\NormalTok{loadings\_mil}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]         [,2]        [,3]        [,4]
## [1,]  0.04083715  0.723859293  0.60196083  0.33466881
## [2,] -0.01055112  0.689576596 -0.63020980 -0.35666286
## [3,]  0.99824759 -0.022442542 -0.01090193 -0.05365844
## [4,]  0.04150602  0.002859015 -0.49026515  0.87057979
\end{verbatim}

Petal.Length accounts for the highest influence on the first principal
component - which is logical, as its measure is now different and model
consideres it as 10 times increase, not as another measure

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_iris\_mil }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(iris\_cut\_mil) }\CommentTok{\# correlation matrix}
\NormalTok{eigen\_decomposition\_cor\_mil }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(cor\_iris\_mil)}
\NormalTok{loadings\_cor\_mil }\OtherTok{\textless{}{-}}\NormalTok{ eigen\_decomposition\_cor\_mil}\SpecialCharTok{$}\NormalTok{vectors}
\NormalTok{loadings\_cor\_mil}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]        [,2]       [,3]       [,4]
## [1,]  0.5210659 -0.37741762  0.7195664  0.2612863
## [2,] -0.2693474 -0.92329566 -0.2443818 -0.1235096
## [3,]  0.5804131 -0.02449161 -0.1421264 -0.8014492
## [4,]  0.5648565 -0.06694199 -0.6342727  0.5235971
\end{verbatim}

However, calculations based on correlation matrix are not influenced by
this change at all, which is also logical, considering that prior
correlation hasn't changed by changing the measumement This leads us to
the conclusion that having equal weights (correlation matrix) can be
useful while modeling different types of variables, while using
covariation matrix helps to understand the actual weight of each
variable

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  PC plot
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca\_data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(pca}\SpecialCharTok{$}\NormalTok{x[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{])}
\NormalTok{pca\_data}\SpecialCharTok{$}\NormalTok{Species }\OtherTok{\textless{}{-}}\NormalTok{ iris}\SpecialCharTok{$}\NormalTok{Species}
\FunctionTok{ggplot}\NormalTok{(pca\_data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ PC1, }\AttributeTok{y =}\NormalTok{ PC2, }\AttributeTok{color =}\NormalTok{ Species)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
       \AttributeTok{x =} \StringTok{"First principal component"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Second principal component"}
\NormalTok{       ) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-95-1.pdf}}

\subsubsection{Exercise 10}\label{exercise-10}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  AR(2) fit
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(cmort)}
\NormalTok{cmort }\OtherTok{\textless{}{-}}\NormalTok{ cmort}
\NormalTok{cmort}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time Series:
## Start = c(1970, 1) 
## End = c(1979, 40) 
## Frequency = 52 
##   [1]  97.85 104.64  94.36  98.05  95.85  95.98  88.63  90.85  92.06  88.75
##  [11]  94.60  92.86  98.02  87.64  97.40  83.24  86.60  90.69  82.86  99.06
##  [21]  81.00  93.18  86.86  89.35  87.13  88.39  85.38  83.96  84.95  86.81
##  [31]  85.25  94.72  90.96  87.73  92.58  87.02  92.68  97.95  94.19  93.95
##  [41]  92.29  93.48  97.41  96.98 106.60 112.41 118.59 107.90 111.82 102.78
##  [51] 100.63 106.54 105.39 104.99 102.72 104.67 103.30  98.46 100.78  94.43
##  [61]  92.16  92.13  95.04  86.88  95.29  85.39  92.63  88.72  87.09  83.92
##  [71]  89.01  78.14  92.84  88.65  86.66  82.04 105.15  94.19  83.99  88.22
##  [81]  85.59  99.21  87.77  90.39  82.25 102.92  86.84  97.22  94.97 104.86
##  [91]  80.53 102.47  97.80  95.28 105.64 106.44 110.65 114.41 115.98 112.72
## [101] 115.99 104.14 109.30 111.47 102.67 101.34  94.97  90.48  93.70  81.87
## [111]  91.12  90.55  89.62  91.63  89.22  84.81  95.00  83.77  98.26  82.87
## [121]  85.51  84.67  84.45  93.96  82.47  89.18  87.33  92.67  93.83  86.65
## [131]  89.35  77.97  86.06  83.34  87.35  90.58  84.72  88.32  82.62  92.52
## [141]  86.73  99.54  95.50  92.34  97.49  97.90  97.54 103.78 110.17 116.04
## [151] 132.04 126.95 121.11 119.30 118.20 102.36  98.44  97.87  92.98  96.16
## [161]  86.83  91.09  92.50  90.64  80.69  99.91  89.09  94.25  93.33  84.08
## [171]  86.37  86.61  82.47  82.73  98.29  87.02  91.13  80.23  81.36  82.80
## [181]  87.24  79.37  86.83  82.00  77.96  79.69  87.32  85.33  92.02  84.03
## [191]  83.45  82.35  89.17  82.24  93.35  89.16  95.13  89.10 100.32  95.61
## [201]  99.61 105.82 104.20  95.45  90.48  93.58  91.71  95.29  94.69 102.50
## [211]  98.58 107.12  99.29  96.85  89.02  96.27  97.55  85.16  94.77  85.45
## [221]  97.46  83.31  91.41  88.84  86.44  82.08  83.63  95.22  80.28  85.59
## [231]  84.68  81.53  89.20  74.51  81.85  81.97  85.01  86.98  81.67  91.11
## [241]  83.38  86.18  89.93  91.82  92.27  89.29  85.41  96.78  83.60  98.63
## [251]  90.86  94.36  97.52 108.68 107.23 107.08 113.39 105.51 111.90 110.44
## [261]  95.42  97.78  90.38  86.89  91.59  85.51  88.16  87.03  88.61  96.96
## [271]  80.03  80.53  76.46  78.85  87.03  82.27  78.92  72.75  77.75  83.79
## [281]  82.13  76.42  74.58  79.61  76.52  79.27  74.70  75.49  82.82  80.29
## [291]  80.05  78.64  79.40  71.02  73.55  79.60  85.08  90.14  82.26  86.75
## [301]  90.11  94.86  89.68  90.16  85.73  96.82 100.37  93.43  94.12  89.26
## [311]  91.81  97.40 102.71 101.94  97.40  96.12 105.45  94.34  92.51  88.47
## [321]  85.47  85.70  84.48  85.63  79.67  80.78  74.58  76.32  80.37  83.30
## [331]  82.98  91.34  78.57  76.68  76.47  73.66  78.61  83.40  71.96  77.17
## [341]  72.38  79.52  72.05  75.86  74.32  77.70  82.99  77.79  77.42  85.55
## [351]  85.33  82.16  83.74  84.40  90.32  82.74  91.50  96.23  92.90  92.30
## [361]  91.76  92.34  78.91  88.06  81.91  79.68  83.20  84.05  85.80  84.39
## [371]  91.74  90.65  89.67  86.24  91.46  83.30  83.05  74.14  90.12  83.84
## [381]  79.94  74.65  77.89  78.06  74.96  77.90  73.65  79.32  82.91  79.48
## [391]  73.21  76.46  73.76  68.11  76.53  68.46  72.84  79.92  73.26  79.55
## [401]  77.02  78.39  81.86  88.20  75.69  88.85  82.52  87.44  82.91  92.84
## [411]  91.85  89.82  96.84  99.56 105.10  95.70  93.46  99.27  90.39  85.85
## [421]  86.69  92.94  86.63  89.78  83.22  86.04  81.53  77.46  76.63  82.09
## [431]  81.22  70.96  80.17  78.48  76.80  77.63  74.31  76.30  85.97  73.07
## [441]  76.29  75.21  79.18  78.25  77.24  81.55  75.46  76.86  88.43  92.93
## [451]  77.65  78.74  73.63  82.11  80.81  84.34  83.48  76.40  92.77  88.09
## [461]  96.20 100.28 107.58  93.73  87.33  88.11  88.07 100.81  95.52  91.14
## [471]  85.67  88.24  88.61  85.64  87.29  83.92  89.15  87.61  81.99  84.86
## [481]  81.17  87.33  86.40  85.90  79.01  83.49  87.88  74.94  80.32  81.75
## [491]  78.68  74.62  74.16  71.50  75.89  74.89  77.36  73.63  81.17  83.91
## [501]  82.36  79.74  73.46  79.03  76.56  78.52  89.43  85.49
\end{verbatim}

Let's look at the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(cmort)}
\FunctionTok{invisible}\NormalTok{(}\FunctionTok{acf2}\NormalTok{(cmort, }\AttributeTok{max.lag =}\NormalTok{ n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-97-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{invisible}\NormalTok{(}\FunctionTok{acf2}\NormalTok{(cmort, }\AttributeTok{max.lag =} \DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{Exercises_files/figure-latex/unnamed-chunk-97-2.pdf}}

There is definitely some time trend in the data Drop after second lag in
PACF indicates that AR(2) may be a good model to fit

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cmort\_lags }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ cmort[}\DecValTok{3}\SpecialCharTok{:}\NormalTok{n],}
  \AttributeTok{x\_1 =}\NormalTok{ cmort[}\DecValTok{2}\SpecialCharTok{:}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{)],}
  \AttributeTok{x\_2 =}\NormalTok{ cmort[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{(n}\DecValTok{{-}2}\NormalTok{)]}
\NormalTok{)}

\CommentTok{\# Fit the AR(2) model using linear regression}
\NormalTok{cmort\_AR2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(x }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x\_1 }\SpecialCharTok{+}\NormalTok{ x\_2, }\AttributeTok{data =}\NormalTok{ cmort\_lags)}

\CommentTok{\# Output the model summary}
\FunctionTok{summary}\NormalTok{(cmort\_AR2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = x ~ x_1 + x_2, data = cmort_lags)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.8192  -4.0339  -0.2112   3.4219  22.1840 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 11.45061    2.40080   4.769 2.42e-06 ***
## x_1          0.42859    0.03991  10.738  < 2e-16 ***
## x_2          0.44179    0.03988  11.078  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.702 on 503 degrees of freedom
## Multiple R-squared:  0.6752, Adjusted R-squared:  0.6739 
## F-statistic: 522.8 on 2 and 503 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coefs\_AR2 }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(cmort\_AR2)}
\end{Highlighting}
\end{Shaded}


\end{document}
